# quality-assess

Comprehensive code quality assessment and validation with automated analysis, compliance checking, and improvement recommendations.

## Usage
```bash
npx claude-flow analysis quality-assess [options]
```

## MCP Command
```javascript
mcp__claude-flow__quality_assess({
  "target": "string",
  "criteria": "array",
  "compliance_standards": "array",
  "depth": "string",
  "auto_fix": "boolean"
})
```

## Assessment Types

### Code Quality Analysis
- `code-review` - Automated code review with best practices checking
- `architecture-review` - System architecture and design patterns analysis
- `security-scan` - Security vulnerability and compliance assessment
- `performance-review` - Performance optimization opportunities
- `maintainability` - Code maintainability and technical debt analysis

### Compliance Assessment
- `standards-compliance` - Industry standards compliance (ISO, NIST, etc.)
- `coding-standards` - Language-specific coding standards adherence
- `accessibility` - Web accessibility compliance (WCAG, ADA)
- `security-compliance` - Security standards compliance (OWASP, SOC2)
- `regulatory-compliance` - Regulatory requirements (GDPR, HIPAA, etc.)

## Options

### Target Selection
- `--target <scope>` - Assessment scope: `current-file`, `current-project`, `repository`, `codebase`
- `--files <pattern>` - Specific file patterns to assess
- `--exclude <pattern>` - Files/directories to exclude from assessment
- `--language <lang>` - Focus on specific programming language

### Assessment Criteria
- `--criteria <types>` - Quality criteria: `all`, `security`, `performance`, `maintainability`, `standards`
- `--standards <list>` - Compliance standards to check against
- `--severity <level>` - Minimum issue severity: `low`, `medium`, `high`, `critical`
- `--custom-rules <file>` - Custom quality rules configuration

### Analysis Depth
- `--depth <level>` - Analysis depth: `surface`, `standard`, `deep`, `comprehensive`
- `--include-dependencies` - Include external dependencies in assessment
- `--cross-file-analysis` - Analyze relationships between files
- `--architectural-analysis` - Include system architecture assessment

### Automation Options
- `--auto-fix` - Automatically fix identified issues where possible
- `--suggestions` - Generate improvement suggestions
- `--priority-ranking` - Rank issues by business impact
- `--remediation-plan` - Generate step-by-step remediation plan

### Reporting Options
- `--export <format>` - Export format: `json`, `html`, `pdf`, `csv`, `sonarqube`
- `--report-type <type>` - Report type: `summary`, `detailed`, `executive`, `technical`
- `--baseline <file>` - Compare against quality baseline
- `--trend-analysis` - Include quality trend analysis

## Detailed Examples

### Basic Quality Assessment
```bash
# Quick quality overview of current project
npx claude-flow analysis quality-assess --target current-project

# Comprehensive quality analysis
npx claude-flow analysis quality-assess \
  --target repository \
  --criteria all \
  --depth comprehensive \
  --export quality-report.html
```

### Security-Focused Assessment
```bash
# Security vulnerability scan
npx claude-flow analysis quality-assess \
  --criteria security \
  --standards owasp,nist \
  --severity medium \
  --auto-fix \
  --export security-assessment.pdf

# Compliance check for specific standards
npx claude-flow analysis quality-assess \
  --standards-compliance \
  --standards soc2,gdpr,hipaa \
  --regulatory-compliance \
  --export compliance-report.json
```

### Performance Quality Analysis
```bash
# Performance optimization assessment
npx claude-flow analysis quality-assess \
  --criteria performance \
  --depth deep \
  --include-dependencies \
  --suggestions \
  --priority-ranking

# Architecture quality review
npx claude-flow analysis quality-assess \
  --architecture-review \
  --cross-file-analysis \
  --architectural-analysis \
  --export architecture-assessment.pdf
```

### Automated Quality Management
```bash
# Auto-fix quality issues
npx claude-flow analysis quality-assess \
  --auto-fix \
  --criteria maintainability,standards \
  --severity high \
  --remediation-plan \
  --export remediation-plan.json

# Quality trend monitoring
npx claude-flow analysis quality-assess \
  --baseline quality-baseline.json \
  --trend-analysis \
  --report-type executive \
  --export monthly-quality-trends.pdf
```

## Quality Assessment Dashboard

### Code Quality Metrics
```
ğŸ¯ Code Quality Assessment Report

Overall Quality Score: 8.7/10 (+0.3 vs baseline)
â”œâ”€â”€ Code Structure: 9.1/10 (Excellent)
â”œâ”€â”€ Security: 8.9/10 (Very Good)
â”œâ”€â”€ Performance: 8.2/10 (Good)
â”œâ”€â”€ Maintainability: 8.8/10 (Very Good)
â”œâ”€â”€ Documentation: 7.9/10 (Good)
â””â”€â”€ Test Coverage: 9.4/10 (Excellent)

ğŸ“Š Quality by Component
â”œâ”€â”€ Backend Services: 8.9/10
â”‚   â”œâ”€â”€ API Endpoints: 9.2/10
â”‚   â”œâ”€â”€ Business Logic: 8.7/10
â”‚   â”œâ”€â”€ Data Layer: 8.5/10
â”‚   â””â”€â”€ Security Layer: 9.4/10
â”‚
â”œâ”€â”€ Frontend Application: 8.3/10
â”‚   â”œâ”€â”€ Component Structure: 8.8/10
â”‚   â”œâ”€â”€ State Management: 8.1/10
â”‚   â”œâ”€â”€ User Interface: 8.5/10
â”‚   â””â”€â”€ Performance: 7.8/10
â”‚
â”œâ”€â”€ Database Design: 9.0/10
â”‚   â”œâ”€â”€ Schema Design: 9.2/10
â”‚   â”œâ”€â”€ Query Optimization: 8.9/10
â”‚   â”œâ”€â”€ Indexing Strategy: 8.8/10
â”‚   â””â”€â”€ Data Integrity: 9.1/10
â”‚
â””â”€â”€ Infrastructure: 8.5/10
    â”œâ”€â”€ Configuration: 8.7/10
    â”œâ”€â”€ Monitoring: 8.2/10
    â”œâ”€â”€ Security: 8.9/10
    â””â”€â”€ Scalability: 8.3/10

ğŸ† Quality Achievements
â”œâ”€â”€ Zero critical security vulnerabilities
â”œâ”€â”€ 94% test coverage (industry leading)
â”œâ”€â”€ 97% coding standards compliance
â”œâ”€â”€ 89% performance optimization opportunities addressed
â””â”€â”€ 92% documentation completeness
```

### Security Assessment Results
```
ğŸ”’ Security Quality Assessment

Security Score: 8.9/10 (Very High)
â”œâ”€â”€ Vulnerability Count: 0 Critical, 2 High, 7 Medium, 12 Low
â”œâ”€â”€ Security Standards Compliance: 97%
â”œâ”€â”€ Encryption Implementation: 9.4/10
â”œâ”€â”€ Authentication & Authorization: 9.1/10
â”œâ”€â”€ Data Protection: 8.8/10
â””â”€â”€ Network Security: 8.7/10

ğŸ›¡ï¸ Security Analysis by Category
â”œâ”€â”€ Input Validation: 9.2/10
â”‚   â”œâ”€â”€ SQL Injection Protection: âœ… Excellent
â”‚   â”œâ”€â”€ XSS Prevention: âœ… Excellent
â”‚   â”œâ”€â”€ CSRF Protection: âœ… Implemented
â”‚   â””â”€â”€ Input Sanitization: âœ… Comprehensive
â”‚
â”œâ”€â”€ Authentication Security: 9.1/10
â”‚   â”œâ”€â”€ Password Policies: âœ… Strong
â”‚   â”œâ”€â”€ Multi-Factor Auth: âœ… Implemented
â”‚   â”œâ”€â”€ Session Management: âœ… Secure
â”‚   â””â”€â”€ Token Security: âœ… JWT Best Practices
â”‚
â”œâ”€â”€ Data Security: 8.8/10
â”‚   â”œâ”€â”€ Encryption at Rest: âœ… AES-256
â”‚   â”œâ”€â”€ Encryption in Transit: âœ… TLS 1.3
â”‚   â”œâ”€â”€ Key Management: âœ… Secure Vault
â”‚   â””â”€â”€ Data Masking: âš ï¸ Partial Implementation
â”‚
â”œâ”€â”€ Infrastructure Security: 8.7/10
â”‚   â”œâ”€â”€ Container Security: âœ… Hardened Images
â”‚   â”œâ”€â”€ Network Segmentation: âœ… Proper Isolation
â”‚   â”œâ”€â”€ Access Controls: âœ… Principle of Least Privilege
â”‚   â””â”€â”€ Monitoring & Logging: âœ… Comprehensive
â”‚
â””â”€â”€ Compliance Status: 97%
    â”œâ”€â”€ OWASP Top 10: âœ… 100% Compliant
    â”œâ”€â”€ NIST Framework: âœ… 95% Compliant
    â”œâ”€â”€ SOC2 Type II: âœ… 98% Compliant
    â””â”€â”€ GDPR Requirements: âœ… 94% Compliant

ğŸš¨ Security Issues Identified
High Priority (2 issues):
1. API Rate Limiting: Insufficient protection against brute force
2. Log Sanitization: Potential sensitive data in logs

Medium Priority (7 issues):
â”œâ”€â”€ Password history enforcement needs improvement
â”œâ”€â”€ Session timeout configuration could be optimized
â”œâ”€â”€ Some endpoints lack request size limits
â”œâ”€â”€ Certificate pinning not implemented for mobile
â”œâ”€â”€ Security headers could be enhanced
â”œâ”€â”€ Dependency vulnerabilities in 3 packages
â””â”€â”€ Error messages could leak system information

Remediation Timeline: 5 days for high priority, 2 weeks for medium priority
```

### Performance Quality Analysis
```
âš¡ Performance Quality Assessment

Performance Score: 8.2/10 (Good)
â”œâ”€â”€ Response Time: 8.5/10 (Average: 245ms)
â”œâ”€â”€ Throughput: 8.1/10 (1,247 req/sec peak)
â”œâ”€â”€ Resource Utilization: 7.8/10 (68% CPU avg)
â”œâ”€â”€ Scalability: 8.4/10 (Linear scaling to 10x load)
â”œâ”€â”€ Database Performance: 8.7/10 (Average query: 45ms)
â””â”€â”€ Frontend Performance: 7.6/10 (LCP: 1.8s, FID: 85ms)

ğŸƒâ€â™‚ï¸ Performance by Component
â”œâ”€â”€ API Response Times:
â”‚   â”œâ”€â”€ Authentication: 123ms average (Target: <150ms) âœ…
â”‚   â”œâ”€â”€ Data Retrieval: 89ms average (Target: <100ms) âœ…
â”‚   â”œâ”€â”€ Complex Queries: 267ms average (Target: <300ms) âœ…
â”‚   â””â”€â”€ File Operations: 445ms average (Target: <500ms) âœ…
â”‚
â”œâ”€â”€ Database Performance:
â”‚   â”œâ”€â”€ Query Optimization: 8.9/10
â”‚   â”œâ”€â”€ Index Usage: 94% (Excellent)
â”‚   â”œâ”€â”€ Connection Pooling: 8.7/10
â”‚   â””â”€â”€ Slow Queries: 3% (Target: <5%) âœ…
â”‚
â”œâ”€â”€ Frontend Performance:
â”‚   â”œâ”€â”€ First Contentful Paint: 1.2s (Target: <1.5s) âœ…
â”‚   â”œâ”€â”€ Largest Contentful Paint: 1.8s (Target: <2.5s) âœ…
â”‚   â”œâ”€â”€ Cumulative Layout Shift: 0.08 (Target: <0.1) âœ…
â”‚   â””â”€â”€ Time to Interactive: 2.1s (Target: <3.0s) âœ…
â”‚
â””â”€â”€ Infrastructure Performance:
    â”œâ”€â”€ CPU Utilization: 68% average (Target: <80%) âœ…
    â”œâ”€â”€ Memory Usage: 72% average (Target: <85%) âœ…
    â”œâ”€â”€ Network Latency: 23ms average (Target: <50ms) âœ…
    â””â”€â”€ Disk I/O: 45% utilization (Target: <70%) âœ…

ğŸ¯ Performance Optimization Opportunities
High Impact Optimizations:
1. Image Optimization: -23% load time improvement
2. Database Query Caching: -34% response time improvement
3. CDN Implementation: -18% global latency reduction
4. Code Splitting: -27% initial bundle size reduction

Medium Impact Optimizations:
â”œâ”€â”€ Compression optimization: -12% transfer size
â”œâ”€â”€ Lazy loading implementation: -15% initial load time
â”œâ”€â”€ Connection optimization: -8% connection time
â””â”€â”€ Memory leak prevention: -5% memory usage

Performance Target Achievement:
â”œâ”€â”€ Response Time Targets: 94% met
â”œâ”€â”€ Throughput Targets: 89% met
â”œâ”€â”€ Resource Utilization: 91% within targets
â””â”€â”€ User Experience Metrics: 87% meet Core Web Vitals
```

## Code Quality Standards

### Coding Standards Compliance
```
ğŸ“‹ Coding Standards Assessment

Overall Compliance: 97% (Excellent)
â”œâ”€â”€ Language-Specific Standards: 98%
â”œâ”€â”€ Team Coding Guidelines: 96%
â”œâ”€â”€ Industry Best Practices: 95%
â”œâ”€â”€ Documentation Standards: 94%
â””â”€â”€ Testing Standards: 99%

ğŸ“Š Compliance by Language
â”œâ”€â”€ TypeScript/JavaScript: 98%
â”‚   â”œâ”€â”€ ESLint Rules: 99% compliance
â”‚   â”œâ”€â”€ Prettier Formatting: 100% compliance
â”‚   â”œâ”€â”€ JSDoc Documentation: 94% compliance
â”‚   â””â”€â”€ Testing Coverage: 94% (Target: 90%)
â”‚
â”œâ”€â”€ Python: 97%
â”‚   â”œâ”€â”€ PEP 8 Compliance: 98%
â”‚   â”œâ”€â”€ Type Hints: 89% coverage
â”‚   â”œâ”€â”€ Docstring Coverage: 92%
â”‚   â””â”€â”€ Black Formatting: 100%
â”‚
â”œâ”€â”€ SQL: 95%
â”‚   â”œâ”€â”€ Naming Conventions: 97%
â”‚   â”œâ”€â”€ Query Optimization: 93%
â”‚   â”œâ”€â”€ Schema Documentation: 91%
â”‚   â””â”€â”€ Security Practices: 98%
â”‚
â””â”€â”€ Configuration Files: 96%
    â”œâ”€â”€ YAML/JSON Formatting: 100%
    â”œâ”€â”€ Environment Variables: 94%
    â”œâ”€â”€ Docker Best Practices: 95%
    â””â”€â”€ CI/CD Standards: 97%

âš ï¸ Standards Violations
High Priority (8 violations):
â”œâ”€â”€ Missing error handling in 3 API endpoints
â”œâ”€â”€ Inconsistent logging format in 2 modules
â”œâ”€â”€ Outdated dependency versions (5 packages)
â”œâ”€â”€ Missing input validation in 2 forms
â”œâ”€â”€ Incomplete documentation for 4 functions
â”œâ”€â”€ Test coverage below 90% in 1 module
â”œâ”€â”€ Hard-coded configuration values (3 instances)
â””â”€â”€ Missing API versioning in 2 endpoints

Medium Priority (15 violations):
â”œâ”€â”€ Variable naming inconsistencies (7 instances)
â”œâ”€â”€ Long function implementations (4 functions)
â”œâ”€â”€ Missing type annotations (6 parameters)
â”œâ”€â”€ Unused imports (8 files)
â”œâ”€â”€ Comment formatting issues (12 comments)
â”œâ”€â”€ Missing return type hints (5 functions)
â”œâ”€â”€ Inconsistent indentation (3 files)
â””â”€â”€ Magic number usage (9 instances)

Auto-Fixable Issues: 78% (23 out of 29 violations)
Estimated Fix Time: 2.5 hours for high priority, 4 hours total
```

### Maintainability Assessment
```
ğŸ”§ Code Maintainability Analysis

Maintainability Score: 8.8/10 (Very Good)
â”œâ”€â”€ Code Complexity: 8.9/10 (Low complexity)
â”œâ”€â”€ Documentation Quality: 7.9/10 (Good coverage)
â”œâ”€â”€ Test Coverage: 9.4/10 (Excellent)
â”œâ”€â”€ Dependency Management: 8.7/10 (Well managed)
â”œâ”€â”€ Code Duplication: 9.1/10 (Minimal duplication)
â””â”€â”€ Technical Debt: 8.5/10 (Low debt ratio)

ğŸ“ˆ Maintainability Metrics
â”œâ”€â”€ Cyclomatic Complexity:
â”‚   â”œâ”€â”€ Average: 2.3 (Target: <5) âœ…
â”‚   â”œâ”€â”€ Maximum: 8 (Target: <10) âœ…
â”‚   â”œâ”€â”€ Functions >10: 0 (Target: 0) âœ…
â”‚   â””â”€â”€ Classes >15: 1 (Target: 0) âš ï¸
â”‚
â”œâ”€â”€ Code Duplication:
â”‚   â”œâ”€â”€ Duplicate Lines: 2.1% (Target: <5%) âœ…
â”‚   â”œâ”€â”€ Duplicate Blocks: 1.3% (Target: <3%) âœ…
â”‚   â”œâ”€â”€ Similar Functions: 3 pairs identified
â”‚   â””â”€â”€ Refactoring Opportunities: 7 identified
â”‚
â”œâ”€â”€ Documentation Coverage:
â”‚   â”œâ”€â”€ Function Documentation: 94%
â”‚   â”œâ”€â”€ Class Documentation: 89%
â”‚   â”œâ”€â”€ API Documentation: 96%
â”‚   â”œâ”€â”€ README Completeness: 87%
â”‚   â””â”€â”€ Inline Comments: 78%
â”‚
â”œâ”€â”€ Test Coverage:
â”‚   â”œâ”€â”€ Unit Tests: 94% coverage
â”‚   â”œâ”€â”€ Integration Tests: 87% coverage
â”‚   â”œâ”€â”€ End-to-End Tests: 78% coverage
â”‚   â”œâ”€â”€ Mutation Testing: 89% score
â”‚   â””â”€â”€ Test Quality Score: 9.2/10
â”‚
â””â”€â”€ Dependency Health:
    â”œâ”€â”€ Outdated Dependencies: 5 packages
    â”œâ”€â”€ Security Vulnerabilities: 2 low severity
    â”œâ”€â”€ License Compatibility: 100% compatible
    â”œâ”€â”€ Bundle Size Impact: Optimized
    â””â”€â”€ Update Effort: Low (2 hours estimated)

ğŸš§ Technical Debt Analysis
Total Technical Debt: 12.5 hours (Low)
â”œâ”€â”€ Code Debt: 4.2 hours
â”‚   â”œâ”€â”€ Refactoring opportunities: 7 items
â”‚   â”œâ”€â”€ Code smell fixes: 12 items
â”‚   â””â”€â”€ Architecture improvements: 3 items
â”‚
â”œâ”€â”€ Documentation Debt: 3.1 hours
â”‚   â”œâ”€â”€ Missing documentation: 15 items
â”‚   â”œâ”€â”€ Outdated documentation: 8 items
â”‚   â””â”€â”€ Example updates needed: 5 items
â”‚
â”œâ”€â”€ Test Debt: 2.8 hours
â”‚   â”œâ”€â”€ Missing test cases: 18 items
â”‚   â”œâ”€â”€ Flaky tests: 3 items
â”‚   â””â”€â”€ Test optimization: 6 items
â”‚
â””â”€â”€ Infrastructure Debt: 2.4 hours
    â”œâ”€â”€ Configuration updates: 4 items
    â”œâ”€â”€ Monitoring improvements: 3 items
    â””â”€â”€ Security updates: 5 items

Debt Reduction Priority:
1. Critical path refactoring (1.5 hours)
2. Security-related updates (1.2 hours)
3. Test coverage improvements (2.1 hours)
4. Documentation updates (1.8 hours)
```

## Automated Quality Improvements

### Auto-Fix Capabilities
```
ğŸ”„ Automated Quality Fixes

Auto-Fix Success Rate: 78% (23/29 issues)
â”œâ”€â”€ Code Formatting: 100% success (12/12 issues)
â”œâ”€â”€ Import Organization: 100% success (8/8 issues)
â”œâ”€â”€ Simple Refactoring: 85% success (11/13 issues)
â”œâ”€â”€ Documentation Generation: 67% success (4/6 issues)
â”œâ”€â”€ Test Generation: 45% success (9/20 opportunities)
â””â”€â”€ Security Fixes: 90% success (9/10 issues)

âœ… Successfully Auto-Fixed:
â”œâ”€â”€ Code Formatting & Style (12 issues)
â”‚   â”œâ”€â”€ Indentation standardization
â”‚   â”œâ”€â”€ Line length optimization
â”‚   â”œâ”€â”€ Bracket and spacing consistency
â”‚   â””â”€â”€ Import statement organization
â”‚
â”œâ”€â”€ Code Quality Improvements (11 issues)
â”‚   â”œâ”€â”€ Unused variable removal
â”‚   â”œâ”€â”€ Dead code elimination
â”‚   â”œâ”€â”€ Simple complexity reduction
â”‚   â”œâ”€â”€ Magic number extraction
â”‚   â””â”€â”€ Variable name improvements
â”‚
â”œâ”€â”€ Security Enhancements (9 issues)
â”‚   â”œâ”€â”€ Input validation additions
â”‚   â”œâ”€â”€ SQL injection prevention
â”‚   â”œâ”€â”€ XSS protection implementation
â”‚   â”œâ”€â”€ CSRF token additions
â”‚   â””â”€â”€ Secure header configurations
â”‚
â””â”€â”€ Documentation Updates (4 issues)
    â”œâ”€â”€ Missing function docstrings
    â”œâ”€â”€ Parameter documentation
    â”œâ”€â”€ Return type documentation
    â””â”€â”€ Example code updates

ğŸ”§ Manual Fix Required (6 issues):
â”œâ”€â”€ Complex architectural changes (2 issues)
â”œâ”€â”€ Business logic modifications (1 issue)
â”œâ”€â”€ Database schema updates (1 issue)
â”œâ”€â”€ API contract changes (1 issue)
â””â”€â”€ Performance optimizations requiring analysis (1 issue)

Post-Fix Quality Score: 9.2/10 (+0.4 improvement)
Estimated Manual Fix Time: 6.5 hours
ROI of Auto-Fixes: 340% (23 hours saved vs implementation cost)
```

### Quality Improvement Recommendations
```
ğŸ’¡ Quality Improvement Roadmap

Phase 1: Quick Wins (1-2 weeks)
â”œâ”€â”€ Implement remaining auto-fixes (0.5 days)
â”œâ”€â”€ Update outdated dependencies (1 day)
â”œâ”€â”€ Add missing unit tests (2 days)
â”œâ”€â”€ Improve documentation coverage (1.5 days)
â”œâ”€â”€ Fix security vulnerabilities (1 day)
â””â”€â”€ Expected Quality Gain: +0.6 points

Phase 2: Medium Impact (2-4 weeks)
â”œâ”€â”€ Refactor complex functions (3 days)
â”œâ”€â”€ Implement caching strategies (2 days)
â”œâ”€â”€ Enhance error handling (2 days)
â”œâ”€â”€ Optimize database queries (2 days)
â”œâ”€â”€ Improve API response times (3 days)
â””â”€â”€ Expected Quality Gain: +0.8 points

Phase 3: Strategic Improvements (1-2 months)
â”œâ”€â”€ Architecture modernization (2 weeks)
â”œâ”€â”€ Performance optimization (1 week)
â”œâ”€â”€ Advanced security features (1 week)
â”œâ”€â”€ Monitoring and observability (3 days)
â”œâ”€â”€ Load testing and scaling (1 week)
â””â”€â”€ Expected Quality Gain: +1.1 points

Target Quality Score: 9.7/10 (vs current 8.7/10)
Total Investment: 7 weeks effort
Expected ROI: 245% (reduced maintenance, faster development)
Risk Mitigation: Phased approach, continuous testing, rollback plans
```

## Integration Examples

### Claude Code Integration
```javascript
// Comprehensive quality assessment
mcp__claude-flow__quality_assess({
  target: "repository",
  criteria: ["security", "performance", "maintainability"],
  depth: "comprehensive",
  auto_fix: true
})

// Security-focused assessment
mcp__claude-flow__quality_assess({
  target: "current-project",
  criteria: ["security"],
  compliance_standards: ["owasp", "nist", "soc2"],
  auto_fix: false,
  severity: "medium"
})

// Performance quality check
mcp__claude-flow__quality_assess({
  target: "current-file",
  criteria: ["performance"],
  depth: "deep",
  suggestions: true
})
```

### CI/CD Integration
```yaml
# GitHub Actions Quality Gate
name: Quality Assessment
on: [push, pull_request]

jobs:
  quality-gate:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Quality Assessment
        run: |
          npx claude-flow analysis quality-assess \
            --target repository \
            --criteria all \
            --auto-fix \
            --export quality-report.json
      - name: Quality Gate Check
        run: |
          quality_score=$(cat quality-report.json | jq '.overall_score')
          if (( $(echo "$quality_score < 8.0" | bc -l) )); then
            echo "Quality gate failed: Score $quality_score < 8.0"
            exit 1
          fi
```

### Automated Quality Monitoring
```bash
# Daily quality monitoring
npx claude-flow analysis quality-assess \
  --baseline quality-baseline.json \
  --trend-analysis \
  --auto-fix \
  --alert-degradation \
  --export daily-quality-report.json

# Weekly quality review
npx claude-flow analysis quality-assess \
  --comprehensive-review \
  --report-type executive \
  --improvement-roadmap \
  --export weekly-quality-executive.pdf
```

## Best Practices

### Quality Management Strategy
1. **Establish Quality Baselines** - Document current quality metrics
2. **Implement Continuous Assessment** - Automated quality checks in CI/CD
3. **Prioritize Security** - Regular security assessments and compliance checks
4. **Focus on Maintainability** - Reduce technical debt systematically
5. **Monitor Trends** - Track quality improvements over time

### Assessment Frequency
- **Real-time**: Critical security and performance checks
- **Daily**: Code quality and standards compliance
- **Weekly**: Comprehensive quality review and trend analysis
- **Monthly**: Strategic quality planning and roadmap updates

### Quality Gates
- Minimum quality score thresholds for deployment
- Security vulnerability limits (zero critical, limited high)
- Performance benchmarks for user-facing features
- Test coverage requirements for critical components

## Troubleshooting

### Common Quality Issues
- **Low Quality Scores**: Focus on high-impact improvements first
- **Security Violations**: Prioritize critical and high severity issues
- **Performance Problems**: Profile and optimize bottlenecks systematically
- **Compliance Failures**: Review standards requirements and implementation gaps

### Assessment Performance
- Use appropriate depth levels for assessment scope
- Exclude non-critical files from comprehensive assessments
- Cache assessment results for incremental analysis
- Parallel processing for large codebases

## See Also

- **[security-scan](../security/security-scan.md)** - Dedicated security scanning tools
- **[performance-report](./performance-report.md)** - Performance analysis and optimization
- **[error-analysis](./error-analysis.md)** - Error pattern analysis and prevention
- **[productivity-metrics](./productivity-metrics.md)** - Development productivity assessment