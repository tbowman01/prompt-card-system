# token-usage

Comprehensive token usage analysis and optimization tool for efficient resource management and cost control.

## Usage
```bash
npx claude-flow analysis token-usage [options]
```

## MCP Command
```javascript
mcp__claude-flow__token_usage({
  "operation": "string",
  "timeframe": "string",
  "optimization_target": "number",
  "breakdown_type": "string"
})
```

## Operations

### Analysis Operations
- `analyze` - Comprehensive token usage analysis
- `optimize` - Identify and suggest optimizations
- `track` - Continuous token consumption monitoring
- `forecast` - Predict future token requirements
- `compare` - Compare token usage across periods/swarms

### Optimization Operations
- `compress` - Apply token compression techniques
- `cache` - Implement intelligent caching strategies
- `template` - Optimize prompt templates
- `batch` - Implement batch processing optimizations

## Options

### Time & Scope
- `--period <time>` - Analysis period: `1h`, `6h`, `24h`, `7d`, `30d`, `all` (default: 24h)
- `--real-time` - Enable real-time token tracking
- `--historical` - Include historical trend analysis
- `--baseline <file>` - Compare against baseline consumption

### Breakdown Analysis
- `--by-agent` - Break down consumption by individual agents
- `--by-operation` - Analyze by operation type (read, write, analysis, etc.)
- `--by-task-type` - Group by task complexity/category
- `--by-time` - Hourly/daily consumption patterns
- `--by-cost` - Cost-focused analysis and optimization

### Optimization Options
- `--optimize` - Apply automatic optimizations
- `--target <percent>` - Set optimization target (e.g., 20% reduction)
- `--threshold <number>` - Alert threshold for high usage
- `--budget <amount>` - Set token budget and track against it
- `--suggestions` - Generate optimization recommendations

### Export & Reporting
- `--export <format>` - Export format: `csv`, `json`, `xlsx`, `pdf`
- `--report <type>` - Report type: `summary`, `detailed`, `executive`
- `--dashboard` - Update real-time dashboard
- `--alert` - Send alerts for threshold breaches

## Detailed Examples

### Basic Token Analysis
```bash
# Quick token usage overview
npx claude-flow analysis token-usage --period 24h

# Comprehensive analysis with breakdown
npx claude-flow analysis token-usage \
  --period 7d \
  --by-agent \
  --by-operation \
  --export detailed-usage.xlsx
```

### Optimization Focus
```bash
# Identify optimization opportunities
npx claude-flow analysis token-usage \
  --optimize \
  --target 25 \
  --suggestions \
  --export optimization-plan.json

# Apply automatic optimizations
npx claude-flow analysis token-usage \
  --optimize \
  --target 20 \
  --auto-apply \
  --track-results
```

### Budget Management
```bash
# Set up budget tracking
npx claude-flow analysis token-usage \
  --budget 1000000 \
  --period 30d \
  --threshold 80 \
  --alert \
  --dashboard

# Monitor budget in real-time
npx claude-flow analysis token-usage \
  --real-time \
  --budget 1000000 \
  --alert-email admin@company.com
```

### Comparative Analysis
```bash
# Compare current vs previous month
npx claude-flow analysis token-usage \
  --period 30d \
  --compare previous-month \
  --by-cost \
  --export monthly-comparison.pdf

# A/B test token efficiency
npx claude-flow analysis token-usage \
  --compare swarm-a:swarm-b \
  --by-operation \
  --optimization-analysis
```

### Advanced Analytics
```bash
# Predictive analysis
npx claude-flow analysis token-usage \
  --forecast 30d \
  --include-trends \
  --capacity-planning \
  --export forecast-report.json

# Pattern recognition
npx claude-flow analysis token-usage \
  --period 7d \
  --pattern-analysis \
  --anomaly-detection \
  --by-time
```

## Analysis Breakdown

### Agent-Level Analysis
```
ğŸ¤– Token Usage by Agent (Last 24h)
â”œâ”€â”€ coordinator-001: 125,847 tokens (23.4% of total)
â”‚   â”œâ”€â”€ Task orchestration: 89,234 tokens (71%)
â”‚   â”œâ”€â”€ Communication: 28,567 tokens (23%)
â”‚   â””â”€â”€ Status updates: 8,046 tokens (6%)
â”‚
â”œâ”€â”€ coder-001: 158,392 tokens (29.5% of total)
â”‚   â”œâ”€â”€ Code generation: 112,674 tokens (71%)
â”‚   â”œâ”€â”€ Code review: 31,289 tokens (20%)
â”‚   â””â”€â”€ Documentation: 14,429 tokens (9%)
â”‚
â”œâ”€â”€ analyst-001: 97,234 tokens (18.1% of total)
â”‚   â”œâ”€â”€ Data analysis: 68,064 tokens (70%)
â”‚   â”œâ”€â”€ Report generation: 21,456 tokens (22%)
â”‚   â””â”€â”€ Visualization: 7,714 tokens (8%)
â”‚
â””â”€â”€ tester-001: 87,156 tokens (16.2% of total)
    â”œâ”€â”€ Test creation: 52,293 tokens (60%)
    â”œâ”€â”€ Test execution: 26,147 tokens (30%)
    â””â”€â”€ Result analysis: 8,716 tokens (10%)

Total: 468,629 tokens
Average per agent: 117,157 tokens
Efficiency score: 87% (vs 85% baseline)
```

### Operation-Level Analysis
```
ğŸ“Š Token Usage by Operation Type
â”œâ”€â”€ Code Generation: 186,459 tokens (39.8%)
â”‚   â”œâ”€â”€ Average per task: 1,247 tokens
â”‚   â”œâ”€â”€ Most expensive: Complex algorithms (3,456 tokens)
â”‚   â””â”€â”€ Most efficient: Simple functions (342 tokens)
â”‚
â”œâ”€â”€ Analysis & Research: 134,567 tokens (28.7%)
â”‚   â”œâ”€â”€ Data analysis: 89,234 tokens (66%)
â”‚   â”œâ”€â”€ Literature review: 31,289 tokens (23%)
â”‚   â””â”€â”€ Competitive analysis: 14,044 tokens (10%)
â”‚
â”œâ”€â”€ Testing & QA: 78,123 tokens (16.7%)
â”‚   â”œâ”€â”€ Test case generation: 52,293 tokens (67%)
â”‚   â”œâ”€â”€ Bug analysis: 17,614 tokens (23%)
â”‚   â””â”€â”€ Performance testing: 8,216 tokens (11%)
â”‚
â”œâ”€â”€ Communication: 45,234 tokens (9.7%)
â”‚   â”œâ”€â”€ Agent coordination: 28,567 tokens (63%)
â”‚   â”œâ”€â”€ Status updates: 12,345 tokens (27%)
â”‚   â””â”€â”€ Error reporting: 4,322 tokens (10%)
â”‚
â””â”€â”€ Documentation: 24,246 tokens (5.2%)
    â”œâ”€â”€ API documentation: 14,429 tokens (59%)
    â”œâ”€â”€ User guides: 7,234 tokens (30%)
    â””â”€â”€ Technical specs: 2,583 tokens (11%)
```

### Cost Analysis
```
ğŸ’° Token Cost Analysis (Last 30 Days)
â”œâ”€â”€ Total Cost: $1,847.23 (15% under budget)
â”œâ”€â”€ Average Cost/Token: $0.000123
â”œâ”€â”€ Cost/Task: $2.34 average
â”œâ”€â”€ Most Expensive Agent: coder-001 ($687.45)
â”œâ”€â”€ Most Efficient Agent: coordinator-001 ($0.89/task)
â””â”€â”€ Projected Monthly: $2,156 (vs $2,500 budget)

ğŸ¯ Cost by Task Type
â”œâ”€â”€ Complex Development: $8.45/task (18.2% of total cost)
â”œâ”€â”€ Code Review: $1.23/task (31.7% of total cost)
â”œâ”€â”€ Documentation: $0.87/task (12.4% of total cost)
â”œâ”€â”€ Testing: $1.56/task (23.1% of total cost)
â””â”€â”€ Analysis: $2.34/task (14.6% of total cost)
```

### Time-Based Patterns
```
ğŸ•°ï¸ Token Usage Patterns (24-Hour)
 Hour  | Tokens  | % of Total | Avg/Task | Peak Operations
-------|---------|------------|----------|----------------
 00-01 |  8,234  |    1.8%    |  1,029   | Batch processing
 01-02 |  5,678  |    1.2%    |   943    | Background tasks
 02-03 |  3,456  |    0.7%    |   865    | Maintenance
 ...
 09-10 | 32,567  |    6.9%    |  1,347   | Daily standup analysis
 10-11 | 45,789  |    9.8%    |  1,523   | Active development
 11-12 | 52,134  |   11.1%    |  1,678   | Peak productivity
 ...
 14-15 | 48,923  |   10.4%    |  1,456   | Post-lunch coding
 15-16 | 41,678  |    8.9%    |  1,389   | Code reviews
 ...
 22-23 | 12,345  |    2.6%    |  1,123   | Documentation
 23-00 |  6,789  |    1.4%    |   978    | Cleanup tasks

Peak Hours: 11-12 (52,134 tokens)
Low Hours: 02-03 (3,456 tokens)
Efficiency Pattern: Higher token efficiency during focused work hours
```

## Optimization Strategies

### Template Optimization
```
ğŸš€ Prompt Template Optimization

Current Templates Analysis:
â”œâ”€â”€ Code Generation Template: 1,247 avg tokens
â”‚   â”œâ”€â”€ Optimization potential: 23% reduction
â”‚   â”œâ”€â”€ Redundant instructions: 287 tokens
â”‚   â””â”€â”€ Verbose examples: 156 tokens
â”‚
â”œâ”€â”€ Analysis Template: 892 avg tokens
â”‚   â”œâ”€â”€ Optimization potential: 15% reduction
â”‚   â”œâ”€â”€ Repetitive context: 134 tokens
â”‚   â””â”€â”€ Unnecessary formatting: 89 tokens
â”‚
â””â”€â”€ Review Template: 567 avg tokens
    â”œâ”€â”€ Optimization potential: 8% reduction
    â””â”€â”€ Already well-optimized

Recommended Actions:
1. Compress code generation templates (-287 tokens/use)
2. Streamline analysis context (-134 tokens/use)
3. Remove redundant examples (-156 tokens/use)

Estimated Savings: 577 tokens/task average (23% reduction)
Monthly Impact: $1,734 savings
```

### Caching Strategy
```
ğŸ“¦ Intelligent Caching Opportunities

â”œâ”€â”€ Repeated Queries: 34% of all operations
â”‚   â”œâ”€â”€ Identical prompts: 18% (immediate cache hits)
â”‚   â”œâ”€â”€ Similar prompts: 16% (semantic caching)
â”‚   â””â”€â”€ Potential savings: 156,234 tokens/day
â”‚
â”œâ”€â”€ Common Patterns: 28% cache potential
â”‚   â”œâ”€â”€ Code review patterns: 89,234 tokens/week
â”‚   â”œâ”€â”€ Documentation templates: 45,678 tokens/week
â”‚   â””â”€â”€ Standard analyses: 67,890 tokens/week
â”‚
â””â”€â”€ Pre-computation Opportunities: 12% savings
    â”œâ”€â”€ Common calculations: 23,456 tokens/week
    â”œâ”€â”€ Standard reports: 34,567 tokens/week
    â””â”€â”€ Template generations: 12,345 tokens/week

Implementation Priority:
1. Immediate caching (18% savings) - 1 day implementation
2. Semantic caching (16% savings) - 3 days implementation
3. Pre-computation (12% savings) - 5 days implementation

Total Potential Savings: 46% reduction in token usage
```

### Batch Processing Optimization
```
ğŸ“¦ Batch Processing Opportunities

â”œâ”€â”€ Single-Item Processing: 67% of operations
â”‚   â”œâ”€â”€ Setup overhead: 234 tokens per operation
â”‚   â”œâ”€â”€ Context repetition: 156 tokens per operation
â”‚   â””â”€â”€ Batch potential: 78% of single operations
â”‚
â”œâ”€â”€ Batchable Operations:
â”‚   â”œâ”€â”€ Code reviews: 45 operations/day (batch size: 5-8)
â”‚   â”œâ”€â”€ Documentation: 23 operations/day (batch size: 3-5)
â”‚   â”œâ”€â”€ Testing: 67 operations/day (batch size: 8-12)
â”‚   â””â”€â”€ Analysis: 34 operations/day (batch size: 4-6)
â”‚
â””â”€â”€ Estimated Savings:
    â”œâ”€â”€ Setup overhead reduction: 89,234 tokens/week
    â”œâ”€â”€ Context sharing: 45,678 tokens/week
    â””â”€â”€ Total batch savings: 31% reduction

Optimal Batch Sizes:
- Code Reviews: 6 items (optimal efficiency)
- Documentation: 4 items (quality vs speed balance)
- Testing: 10 items (maximum throughput)
- Analysis: 5 items (context coherence)
```

## Performance Metrics

### Efficiency Indicators
```
ğŸ“ˆ Token Efficiency Metrics
â”œâ”€â”€ Tokens per Task: 1,247 average (vs 1,456 baseline)
â”œâ”€â”€ Efficiency Score: 87% (target: 90%)
â”œâ”€â”€ Waste Ratio: 13% (tokens for failed/retried operations)
â”œâ”€â”€ Cache Hit Rate: 34% (target: 50%)
â””â”€â”€ Optimization Rate: 67% of recommendations applied

ğŸ¯ Quality vs Efficiency Balance
â”œâ”€â”€ Output Quality: 8.7/10 (maintained during optimization)
â”œâ”€â”€ Task Success Rate: 98.7% (no degradation)
â”œâ”€â”€ Agent Satisfaction: 9.1/10 (improved with optimization)
â””â”€â”€ User Experience: 8.9/10 (faster responses, same quality)
```

### Trend Analysis
```
ğŸ“… 30-Day Token Usage Trends

 Week 1: 1,234,567 tokens (baseline)
 Week 2: 1,189,234 tokens (-3.7% optimization applied)
 Week 3: 1,123,456 tokens (-9.0% caching implemented)
 Week 4: 1,067,890 tokens (-13.5% batch processing added)

Trend: -13.5% reduction over 30 days
Projected Next Month: -18% total reduction
ROI: $2,340 savings vs $890 optimization investment
```

## Budget Management

### Budget Tracking
```
ğŸ’° Token Budget Status
â”œâ”€â”€ Monthly Budget: 10,000,000 tokens
â”œâ”€â”€ Used (Day 15): 4,234,567 tokens (42.3%)
â”œâ”€â”€ Projected Usage: 8,469,134 tokens (84.7%)
â”œâ”€â”€ Remaining Budget: 5,765,433 tokens (57.7%)
â””â”€â”€ Budget Health: Good (15.3% under budget)

âš ï¸ Budget Alerts:
- No critical alerts
- Warning: Peak usage detected on Day 12 (450k tokens)
- Recommendation: Monitor usage during high-activity periods

ğŸ”® Budget Forecast:
- Days to budget limit: 35 days (vs 30-day target)
- Recommended adjustments: Increase batch processing by 20%
- Buffer recommendation: Maintain current optimization strategies
```

### Cost Optimization Roadmap
```
ğŸ—ºï¸ Cost Optimization Roadmap

Phase 1 (Week 1): Quick Wins
â”œâ”€â”€ Template compression: -15% tokens
â”œâ”€â”€ Immediate caching: -18% tokens
â””â”€â”€ Expected savings: $1,200/month

Phase 2 (Week 2-3): Advanced Optimization
â”œâ”€â”€ Semantic caching: -16% additional
â”œâ”€â”€ Batch processing: -20% additional
â””â”€â”€ Expected savings: $2,100/month

Phase 3 (Week 4): AI-Driven Optimization
â”œâ”€â”€ Predictive pre-computation: -12% additional
â”œâ”€â”€ Dynamic template selection: -8% additional
â””â”€â”€ Expected savings: $980/month

Total Projected Savings: $4,280/month (42% cost reduction)
Implementation Cost: $2,500 (one-time)
ROI Timeline: 2.3 months
```

## Alert Configuration

### Usage Thresholds
```bash
# Set up token usage alerts
npx claude-flow analysis token-usage \
  --alert-config \
  --daily-threshold 350000 \
  --weekly-threshold 2000000 \
  --monthly-threshold 8000000 \
  --cost-threshold-percent 85

# Configure notification channels
npx claude-flow analysis token-usage \
  --alert-email admin@company.com \
  --alert-slack #operations \
  --alert-webhook https://alerts.company.com/tokens
```

### Automated Responses
```bash
# Auto-optimization triggers
npx claude-flow analysis token-usage \
  --auto-optimize-threshold 90 \
  --emergency-cache-enable 95 \
  --performance-mode-threshold 98
```

## Integration Examples

### Claude Code Integration
```javascript
// Comprehensive token analysis
mcp__claude-flow__token_usage({
  operation: "analyze",
  timeframe: "7d",
  breakdown_type: "agent,operation,cost",
  include_optimization: true
})

// Real-time optimization
mcp__claude-flow__token_usage({
  operation: "optimize",
  optimization_target: 25,
  auto_apply: true,
  track_results: true
})

// Budget monitoring
mcp__claude-flow__token_usage({
  operation: "track",
  budget: 1000000,
  alert_threshold: 80,
  real_time: true
})
```

### Automated Monitoring
```bash
# Daily token analysis cron job
0 9 * * * npx claude-flow analysis token-usage --period 24h --optimize --auto-apply

# Weekly comprehensive report
0 9 * * 1 npx claude-flow analysis token-usage --period 7d --report executive --export weekly-tokens.pdf

# Real-time monitoring
* * * * * npx claude-flow analysis token-usage --real-time --threshold 95 --alert
```

## Best Practices

### Optimization Strategy
1. **Start with Analysis** - Understand current usage patterns
2. **Implement Quick Wins** - Template optimization and basic caching
3. **Advanced Techniques** - Semantic caching and batch processing
4. **Continuous Monitoring** - Real-time tracking and automated optimization

### Budget Management
- Set realistic budgets based on historical data
- Monitor usage patterns and adjust forecasts
- Implement graduated alerts (warning â†’ critical â†’ emergency)
- Regular optimization review and strategy updates

### Quality Maintenance
- Monitor output quality during optimization
- A/B test optimization strategies
- Maintain baseline performance metrics
- User feedback integration

## Troubleshooting

### Common Issues
- **High Token Usage**: Check for inefficient templates, failed retries
- **Budget Overruns**: Implement emergency optimization, review usage patterns
- **Cache Misses**: Tune semantic similarity thresholds, update cache strategies
- **Quality Degradation**: Reduce optimization aggressiveness, A/B test changes

### Performance Tips
- Use streaming analysis for real-time monitoring
- Implement graduated optimization (start conservative)
- Cache optimization calculations
- Batch optimization operations

## See Also

- **[cost-analysis](./cost-analysis.md)** - Financial impact and ROI analysis
- **[performance-report](./performance-report.md)** - Overall system performance
- **[bottleneck-detect](./bottleneck-detect.md)** - Identify usage bottlenecks
- **[Memory Commands](../memory/README.md)** - Memory optimization strategies
