{"version":3,"sources":["/workspaces/prompt-card-system/backend/src/services/analytics/PredictiveAnalytics.ts"],"sourcesContent":["import * as tf from '@tensorflow/tfjs-node';\nimport { EventStore, AnalyticsEvent } from './EventStore';\nimport { AnalyticsEngine } from './AnalyticsEngine';\nimport { PerformanceMonitor } from '../performance/PerformanceMonitor';\nimport { LRUCache } from 'lru-cache';\nimport { performance } from 'perf_hooks';\n\nexport interface PredictionModel {\n  id: string;\n  name: string;\n  type: 'capacity' | 'anomaly' | 'performance' | 'cost';\n  model: tf.LayersModel;\n  metadata: {\n    trainedAt: Date;\n    accuracy: number;\n    features: string[];\n    targetVariable: string;\n    sampleSize: number;\n    version: string;\n  };\n}\n\nexport interface CapacityPrediction {\n  metric: string;\n  timeframe: '1h' | '6h' | '24h' | '7d' | '30d';\n  currentValue: number;\n  predictedValue: number;\n  confidence: number;\n  threshold: number;\n  willExceedThreshold: boolean;\n  timeToThreshold?: Date;\n  recommendations: string[];\n}\n\nexport interface AnomalyDetection {\n  id: string;\n  metric: string;\n  value: number;\n  expectedValue: number;\n  deviation: number;\n  severity: 'low' | 'medium' | 'high' | 'critical';\n  probability: number;\n  timestamp: Date;\n  context: Record<string, any>;\n  recommendations: string[];\n}\n\nexport interface MLInsight {\n  id: string;\n  type: 'trend' | 'correlation' | 'pattern' | 'forecast';\n  title: string;\n  description: string;\n  confidence: number;\n  impact: 'low' | 'medium' | 'high' | 'critical';\n  data: any;\n  timestamp: Date;\n  recommendations: string[];\n  relatedMetrics: string[];\n}\n\nexport interface TrainingData {\n  features: number[][];\n  labels: number[];\n  timestamps: Date[];\n  metadata: Record<string, any>;\n}\n\nexport class PredictiveAnalytics {\n  private models: Map<string, PredictionModel>;\n  private cache: LRUCache<string, any>;\n  private eventStore: EventStore;\n  private analyticsEngine: AnalyticsEngine;\n  private performanceMonitor: PerformanceMonitor;\n  private isTraining: boolean = false;\n  private lastTrainingTime: Date | null = null;\n  private anomalyThresholds: Map<string, { mean: number; stdDev: number; threshold: number }>;\n\n  constructor() {\n    this.models = new Map();\n    this.cache = new LRUCache({\n      max: 500,\n      ttl: 1000 * 60 * 10 // 10 minutes cache for predictions\n    });\n    this.eventStore = EventStore.getInstance();\n    this.analyticsEngine = AnalyticsEngine.getInstance();\n    this.performanceMonitor = new PerformanceMonitor();\n    this.anomalyThresholds = new Map();\n    \n    // Initialize TensorFlow.js\n    this.initializeTensorFlow();\n    \n    // Load pre-trained models if available\n    this.loadExistingModels();\n  }\n\n  /**\n   * Initialize TensorFlow.js backend\n   */\n  private async initializeTensorFlow(): Promise<void> {\n    try {\n      await tf.ready();\n      console.log('TensorFlow.js backend initialized:', tf.getBackend());\n    } catch (error) {\n      console.error('Failed to initialize TensorFlow.js:', error);\n    }\n  }\n\n  /**\n   * Train capacity planning model\n   */\n  public async trainCapacityModel(\n    metric: string,\n    timeframeDays: number = 30\n  ): Promise<PredictionModel> {\n    if (this.isTraining) {\n      throw new Error('Training already in progress');\n    }\n\n    this.isTraining = true;\n    const startTime = performance.now();\n\n    try {\n      console.log(`Training capacity prediction model for ${metric}...`);\n\n      // Collect training data\n      const trainingData = await this.collectTrainingData(metric, timeframeDays);\n      \n      if (trainingData.features.length < 50) {\n        throw new Error(`Insufficient training data: ${trainingData.features.length} samples`);\n      }\n\n      // Prepare data tensors\n      const { xTrain, yTrain, xValidation, yValidation } = this.prepareTrainingData(trainingData);\n\n      // Create and configure model\n      const model = this.createCapacityModel(trainingData.features[0].length);\n\n      // Train model\n      const history = await this.trainModel(model, xTrain, yTrain, xValidation, yValidation);\n\n      // Evaluate model\n      const accuracy = await this.evaluateModel(model, xValidation, yValidation);\n\n      // Create prediction model object\n      const predictionModel: PredictionModel = {\n        id: `capacity_${metric}_${Date.now()}`,\n        name: `Capacity Prediction for ${metric}`,\n        type: 'capacity',\n        model,\n        metadata: {\n          trainedAt: new Date(),\n          accuracy,\n          features: this.getFeatureNames(),\n          targetVariable: metric,\n          sampleSize: trainingData.features.length,\n          version: '1.0.0'\n        }\n      };\n\n      // Store model\n      this.models.set(predictionModel.id, predictionModel);\n\n      // Save model to disk\n      await this.saveModel(predictionModel);\n\n      this.lastTrainingTime = new Date();\n      console.log(`Capacity model trained in ${(performance.now() - startTime).toFixed(2)}ms with accuracy: ${accuracy.toFixed(4)}`);\n\n      return predictionModel;\n\n    } finally {\n      this.isTraining = false;\n    }\n  }\n\n  /**\n   * Train anomaly detection model\n   */\n  public async trainAnomalyModel(\n    metrics: string[],\n    timeframeDays: number = 30\n  ): Promise<PredictionModel> {\n    if (this.isTraining) {\n      throw new Error('Training already in progress');\n    }\n\n    this.isTraining = true;\n    const startTime = performance.now();\n\n    try {\n      console.log(`Training anomaly detection model for metrics: ${metrics.join(', ')}...`);\n\n      // Collect multi-metric training data\n      const trainingData = await this.collectMultiMetricTrainingData(metrics, timeframeDays);\n      \n      if (trainingData.features.length < 100) {\n        throw new Error(`Insufficient training data: ${trainingData.features.length} samples`);\n      }\n\n      // Calculate statistical thresholds for each metric\n      await this.calculateAnomalyThresholds(trainingData);\n\n      // Create autoencoder for anomaly detection\n      const model = this.createAnomalyModel(trainingData.features[0].length);\n\n      // Prepare training data (anomaly detection is unsupervised)\n      const xTensor = tf.tensor2d(trainingData.features);\n      const { xTrain, xValidation } = this.splitData(xTensor, 0.8);\n\n      // Train autoencoder\n      const history = await model.fit(xTrain, xTrain, {\n        epochs: 100,\n        batchSize: 32,\n        validationData: [xValidation, xValidation],\n        shuffle: true,\n        callbacks: {\n          onEpochEnd: (epoch, logs) => {\n            if (epoch % 10 === 0) {\n              console.log(`Epoch ${epoch}: loss = ${logs?.loss?.toFixed(4)}, val_loss = ${logs?.val_loss?.toFixed(4)}`);\n            }\n          }\n        }\n      });\n\n      // Calculate reconstruction threshold\n      const reconstructionErrors = await this.calculateReconstructionErrors(model, xValidation);\n      const threshold = this.calculateAnomalyThreshold(reconstructionErrors);\n\n      const predictionModel: PredictionModel = {\n        id: `anomaly_${metrics.join('_')}_${Date.now()}`,\n        name: `Anomaly Detection for ${metrics.join(', ')}`,\n        type: 'anomaly',\n        model,\n        metadata: {\n          trainedAt: new Date(),\n          accuracy: threshold,\n          features: metrics,\n          targetVariable: 'anomaly_score',\n          sampleSize: trainingData.features.length,\n          version: '1.0.0'\n        }\n      };\n\n      this.models.set(predictionModel.id, predictionModel);\n      await this.saveModel(predictionModel);\n\n      this.lastTrainingTime = new Date();\n      console.log(`Anomaly model trained in ${(performance.now() - startTime).toFixed(2)}ms`);\n\n      return predictionModel;\n\n    } finally {\n      this.isTraining = false;\n    }\n  }\n\n  /**\n   * Generate capacity predictions\n   */\n  public async predictCapacity(\n    metric: string,\n    timeframe: CapacityPrediction['timeframe'] = '24h'\n  ): Promise<CapacityPrediction> {\n    const cacheKey = `capacity_prediction_${metric}_${timeframe}`;\n    const cached = this.cache.get(cacheKey);\n    \n    if (cached) {\n      return cached;\n    }\n\n    const model = this.findBestModel('capacity', metric);\n    if (!model) {\n      throw new Error(`No capacity model available for metric: ${metric}`);\n    }\n\n    // Get recent data for prediction\n    const recentData = await this.getRecentDataForPrediction(metric, 24); // Last 24 hours\n    \n    if (recentData.length === 0) {\n      throw new Error(`No recent data available for metric: ${metric}`);\n    }\n\n    // Prepare input features\n    const features = this.extractFeatures(recentData);\n    const inputTensor = tf.tensor2d([features]);\n\n    // Make prediction\n    const prediction = model.model.predict(inputTensor) as tf.Tensor;\n    const predictedValue = (await prediction.data())[0];\n\n    // Get current value\n    const currentValue = recentData[recentData.length - 1].value;\n\n    // Calculate confidence based on model accuracy and data variance\n    const confidence = this.calculatePredictionConfidence(model, recentData);\n\n    // Get threshold for this metric\n    const threshold = await this.getMetricThreshold(metric);\n\n    // Determine if threshold will be exceeded\n    const willExceedThreshold = predictedValue > threshold;\n\n    // Estimate time to threshold if applicable\n    const timeToThreshold = willExceedThreshold \n      ? this.estimateTimeToThreshold(recentData, threshold, timeframe)\n      : undefined;\n\n    // Generate recommendations\n    const recommendations = this.generateCapacityRecommendations(\n      metric,\n      currentValue,\n      predictedValue,\n      threshold,\n      willExceedThreshold\n    );\n\n    const result: CapacityPrediction = {\n      metric,\n      timeframe,\n      currentValue,\n      predictedValue,\n      confidence,\n      threshold,\n      willExceedThreshold,\n      timeToThreshold,\n      recommendations\n    };\n\n    // Cache result\n    this.cache.set(cacheKey, result, { ttl: this.getTTLForTimeframe(timeframe) });\n\n    // Cleanup tensors\n    inputTensor.dispose();\n    prediction.dispose();\n\n    return result;\n  }\n\n  /**\n   * Detect anomalies in real-time data\n   */\n  public async detectAnomalies(\n    metrics: string[] = ['cpu_usage', 'memory_usage', 'app_response_time']\n  ): Promise<AnomalyDetection[]> {\n    const cacheKey = `anomaly_detection_${metrics.join('_')}`;\n    const cached = this.cache.get(cacheKey);\n    \n    if (cached) {\n      return cached;\n    }\n\n    const model = this.findBestModel('anomaly', metrics.join('_'));\n    if (!model) {\n      throw new Error(`No anomaly model available for metrics: ${metrics.join(', ')}`);\n    }\n\n    const anomalies: AnomalyDetection[] = [];\n\n    // Get recent data for all metrics\n    const recentDataMap = new Map<string, any[]>();\n    for (const metric of metrics) {\n      const data = await this.getRecentDataForPrediction(metric, 1); // Last hour\n      recentDataMap.set(metric, data);\n    }\n\n    // Process each time window\n    const timeWindows = this.createTimeWindows(recentDataMap, 5); // 5-minute windows\n\n    for (const window of timeWindows) {\n      // Extract features for this time window\n      const features = this.extractAnomalyFeatures(window, metrics);\n      \n      if (features.length === 0) continue;\n\n      // Get expected values using model\n      const inputTensor = tf.tensor2d([features]);\n      const reconstruction = model.model.predict(inputTensor) as tf.Tensor;\n      const reconstructedValues = await reconstruction.data();\n\n      // Calculate reconstruction error\n      const reconstructionError = this.calculateReconstructionError(features, Array.from(reconstructedValues));\n\n      // Check against threshold\n      const threshold = this.anomalyThresholds.get(metrics.join('_'))?.threshold || 0.1;\n      \n      if (reconstructionError > threshold) {\n        // Determine which metrics are anomalous\n        for (let i = 0; i < metrics.length; i++) {\n          const metric = metrics[i];\n          const currentValue = features[i];\n          const expectedValue = reconstructedValues[i];\n          const deviation = Math.abs(currentValue - expectedValue);\n\n          if (deviation > this.getMetricAnomalyThreshold(metric)) {\n            const anomaly: AnomalyDetection = {\n              id: `anomaly_${metric}_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,\n              metric,\n              value: currentValue,\n              expectedValue,\n              deviation,\n              severity: this.determineSeverity(deviation, this.getMetricAnomalyThreshold(metric)),\n              probability: Math.min(reconstructionError / threshold, 1.0),\n              timestamp: window.timestamp,\n              context: {\n                reconstructionError,\n                threshold,\n                allMetrics: Object.fromEntries(\n                  metrics.map((m, idx) => [m, features[idx]])\n                )\n              },\n              recommendations: this.generateAnomalyRecommendations(metric, deviation)\n            };\n\n            anomalies.push(anomaly);\n          }\n        }\n      }\n\n      // Cleanup tensors\n      inputTensor.dispose();\n      reconstruction.dispose();\n    }\n\n    // Cache results for a short time\n    this.cache.set(cacheKey, anomalies, { ttl: 1000 * 60 * 2 }); // 2 minutes\n\n    return anomalies;\n  }\n\n  /**\n   * Generate ML-powered insights\n   */\n  public async generateMLInsights(): Promise<MLInsight[]> {\n    const insights: MLInsight[] = [];\n\n    try {\n      // Correlation analysis\n      const correlationInsights = await this.analyzeCorrelations();\n      insights.push(...correlationInsights);\n\n      // Pattern recognition\n      const patternInsights = await this.recognizePatterns();\n      insights.push(...patternInsights);\n\n      // Trend forecasting\n      const trendInsights = await this.forecastTrends();\n      insights.push(...trendInsights);\n\n      // Performance bottleneck analysis\n      const bottleneckInsights = await this.analyzeBottlenecks();\n      insights.push(...bottleneckInsights);\n\n    } catch (error) {\n      console.error('Error generating ML insights:', error);\n    }\n\n    return insights;\n  }\n\n  /**\n   * Get growth projections for capacity planning\n   */\n  public async getGrowthProjections(\n    metric: string,\n    projectionDays: number = 30\n  ): Promise<{\n    current: number;\n    projected: number;\n    growthRate: number;\n    projectionDates: Date[];\n    projectedValues: number[];\n    confidence: number;\n    recommendations: string[];\n  }> {\n    const model = this.findBestModel('capacity', metric);\n    if (!model) {\n      throw new Error(`No capacity model available for metric: ${metric}`);\n    }\n\n    // Get historical data for trend analysis\n    const historicalData = await this.getRecentDataForPrediction(metric, projectionDays * 3);\n    \n    if (historicalData.length === 0) {\n      throw new Error(`No historical data available for metric: ${metric}`);\n    }\n\n    // Calculate growth rate\n    const growthRate = this.calculateGrowthRate(historicalData);\n\n    // Generate projections\n    const projectionDates: Date[] = [];\n    const projectedValues: number[] = [];\n    const currentValue = historicalData[historicalData.length - 1].value;\n\n    for (let i = 1; i <= projectionDays; i++) {\n      const date = new Date();\n      date.setDate(date.getDate() + i);\n      projectionDates.push(date);\n\n      // Use model to predict future value\n      const features = this.extrapolateFeatures(historicalData, i);\n      const inputTensor = tf.tensor2d([features]);\n      const prediction = model.model.predict(inputTensor) as tf.Tensor;\n      const predictedValue = (await prediction.data())[0];\n      \n      projectedValues.push(predictedValue);\n\n      // Cleanup\n      inputTensor.dispose();\n      prediction.dispose();\n    }\n\n    const projectedValue = projectedValues[projectedValues.length - 1];\n    const confidence = this.calculatePredictionConfidence(model, historicalData);\n\n    // Generate recommendations based on projections\n    const recommendations = this.generateGrowthRecommendations(\n      metric,\n      currentValue,\n      projectedValue,\n      growthRate,\n      projectionDays\n    );\n\n    return {\n      current: currentValue,\n      projected: projectedValue,\n      growthRate,\n      projectionDates,\n      projectedValues,\n      confidence,\n      recommendations\n    };\n  }\n\n  /**\n   * Auto-retrain models based on data drift\n   */\n  public async autoRetrainModels(): Promise<void> {\n    if (this.isTraining) {\n      console.log('Training already in progress, skipping auto-retrain');\n      return;\n    }\n\n    const now = new Date();\n    const shouldRetrain = !this.lastTrainingTime || \n      (now.getTime() - this.lastTrainingTime.getTime()) > (7 * 24 * 60 * 60 * 1000); // 7 days\n\n    if (!shouldRetrain) {\n      return;\n    }\n\n    console.log('Starting auto-retrain of ML models...');\n\n    try {\n      // Retrain capacity models for key metrics\n      const keyMetrics = ['cpu_usage', 'memory_usage', 'app_response_time', 'app_queue_size'];\n      \n      for (const metric of keyMetrics) {\n        try {\n          await this.trainCapacityModel(metric, 30);\n          console.log(`Successfully retrained capacity model for ${metric}`);\n        } catch (error) {\n          console.error(`Failed to retrain capacity model for ${metric}:`, error.message);\n        }\n      }\n\n      // Retrain anomaly detection model\n      try {\n        await this.trainAnomalyModel(keyMetrics, 30);\n        console.log('Successfully retrained anomaly detection model');\n      } catch (error) {\n        console.error('Failed to retrain anomaly detection model:', error.message);\n      }\n\n    } catch (error) {\n      console.error('Error during auto-retrain:', error);\n    }\n  }\n\n  // Private helper methods...\n\n  private async loadExistingModels(): Promise<void> {\n    // Implementation to load saved models from disk\n    console.log('Loading existing ML models...');\n  }\n\n  private async collectTrainingData(metric: string, timeframeDays: number): Promise<TrainingData> {\n    const endTime = new Date();\n    const startTime = new Date(endTime.getTime() - (timeframeDays * 24 * 60 * 60 * 1000));\n\n    const events = await this.eventStore.getEvents({\n      start_time: startTime,\n      end_time: endTime,\n      limit: 10000\n    });\n\n    // Extract relevant data points and features\n    const features: number[][] = [];\n    const labels: number[] = [];\n    const timestamps: Date[] = [];\n\n    // Process events to create training data\n    for (const event of events) {\n      if (event.data[metric] !== undefined) {\n        const featureVector = this.extractFeatures([event]);\n        if (featureVector.length > 0) {\n          features.push(featureVector);\n          labels.push(event.data[metric]);\n          timestamps.push(new Date(event.timestamp));\n        }\n      }\n    }\n\n    return {\n      features,\n      labels,\n      timestamps,\n      metadata: { metric, timeframeDays, eventCount: events.length }\n    };\n  }\n\n  private async collectMultiMetricTrainingData(metrics: string[], timeframeDays: number): Promise<TrainingData> {\n    const endTime = new Date();\n    const startTime = new Date(endTime.getTime() - (timeframeDays * 24 * 60 * 60 * 1000));\n\n    const features: number[][] = [];\n    const labels: number[] = [];\n    const timestamps: Date[] = [];\n\n    // Get data for each metric\n    for (const metric of metrics) {\n      const data = await this.getRecentDataForPrediction(metric, timeframeDays * 24);\n      \n      for (const point of data) {\n        const featureVector = metrics.map(m => \n          m === metric ? point.value : this.getMetricValueAtTime(m, point.timestamp)\n        ).filter(v => v !== undefined && !isNaN(v));\n\n        if (featureVector.length === metrics.length) {\n          features.push(featureVector);\n          labels.push(0); // For unsupervised learning\n          timestamps.push(point.timestamp);\n        }\n      }\n    }\n\n    return {\n      features,\n      labels,\n      timestamps,\n      metadata: { metrics, timeframeDays }\n    };\n  }\n\n  private prepareTrainingData(trainingData: TrainingData): {\n    xTrain: tf.Tensor2D;\n    yTrain: tf.Tensor2D;\n    xValidation: tf.Tensor2D;\n    yValidation: tf.Tensor2D;\n  } {\n    // Normalize features\n    const normalizedFeatures = this.normalizeFeatures(trainingData.features);\n    const normalizedLabels = this.normalizeLabels(trainingData.labels);\n\n    // Split data\n    const splitIndex = Math.floor(normalizedFeatures.length * 0.8);\n    \n    const xTrain = tf.tensor2d(normalizedFeatures.slice(0, splitIndex));\n    const yTrain = tf.tensor2d(normalizedLabels.slice(0, splitIndex), [splitIndex, 1]);\n    const xValidation = tf.tensor2d(normalizedFeatures.slice(splitIndex));\n    const yValidation = tf.tensor2d(normalizedLabels.slice(splitIndex), [normalizedLabels.length - splitIndex, 1]);\n\n    return { xTrain, yTrain, xValidation, yValidation };\n  }\n\n  private createCapacityModel(inputShape: number): tf.LayersModel {\n    const model = tf.sequential({\n      layers: [\n        tf.layers.dense({\n          inputShape: [inputShape],\n          units: 64,\n          activation: 'relu',\n          kernelRegularizer: tf.regularizers.l2({ l2: 0.01 })\n        }),\n        tf.layers.dropout({ rate: 0.2 }),\n        tf.layers.dense({\n          units: 32,\n          activation: 'relu',\n          kernelRegularizer: tf.regularizers.l2({ l2: 0.01 })\n        }),\n        tf.layers.dropout({ rate: 0.2 }),\n        tf.layers.dense({\n          units: 16,\n          activation: 'relu'\n        }),\n        tf.layers.dense({\n          units: 1,\n          activation: 'linear'\n        })\n      ]\n    });\n\n    model.compile({\n      optimizer: tf.train.adam(0.001),\n      loss: 'meanSquaredError',\n      metrics: ['mae']\n    });\n\n    return model;\n  }\n\n  private createAnomalyModel(inputShape: number): tf.LayersModel {\n    // Autoencoder for anomaly detection\n    const model = tf.sequential({\n      layers: [\n        // Encoder\n        tf.layers.dense({\n          inputShape: [inputShape],\n          units: 32,\n          activation: 'relu'\n        }),\n        tf.layers.dense({\n          units: 16,\n          activation: 'relu'\n        }),\n        tf.layers.dense({\n          units: 8,\n          activation: 'relu'\n        }),\n        // Decoder\n        tf.layers.dense({\n          units: 16,\n          activation: 'relu'\n        }),\n        tf.layers.dense({\n          units: 32,\n          activation: 'relu'\n        }),\n        tf.layers.dense({\n          units: inputShape,\n          activation: 'linear'\n        })\n      ]\n    });\n\n    model.compile({\n      optimizer: tf.train.adam(0.001),\n      loss: 'meanSquaredError'\n    });\n\n    return model;\n  }\n\n  private async trainModel(\n    model: tf.LayersModel,\n    xTrain: tf.Tensor2D,\n    yTrain: tf.Tensor2D,\n    xValidation: tf.Tensor2D,\n    yValidation: tf.Tensor2D\n  ): Promise<tf.History> {\n    return await model.fit(xTrain, yTrain, {\n      epochs: 100,\n      batchSize: 32,\n      validationData: [xValidation, yValidation],\n      shuffle: true,\n      callbacks: {\n        onEpochEnd: (epoch, logs) => {\n          if (epoch % 10 === 0) {\n            console.log(`Epoch ${epoch}: loss = ${logs?.loss?.toFixed(4)}, val_loss = ${logs?.val_loss?.toFixed(4)}`);\n          }\n        }\n      }\n    });\n  }\n\n  private async evaluateModel(\n    model: tf.LayersModel,\n    xValidation: tf.Tensor2D,\n    yValidation: tf.Tensor2D\n  ): Promise<number> {\n    const evaluation = model.evaluate(xValidation, yValidation) as tf.Tensor[];\n    const loss = await evaluation[0].data();\n    return 1 - loss[0]; // Convert loss to accuracy-like metric\n  }\n\n  private async saveModel(predictionModel: PredictionModel): Promise<void> {\n    try {\n      const modelPath = `file://./models/${predictionModel.id}`;\n      await predictionModel.model.save(modelPath);\n      console.log(`Model saved to ${modelPath}`);\n    } catch (error) {\n      console.error('Failed to save model:', error);\n    }\n  }\n\n  private findBestModel(type: PredictionModel['type'], target: string): PredictionModel | null {\n    const candidates = Array.from(this.models.values())\n      .filter(model => model.type === type && \n        (model.metadata.targetVariable === target || \n         model.metadata.features.includes(target)))\n      .sort((a, b) => b.metadata.accuracy - a.metadata.accuracy);\n\n    return candidates[0] || null;\n  }\n\n  private getFeatureNames(): string[] {\n    return [\n      'hour_of_day',\n      'day_of_week',\n      'month_of_year',\n      'is_weekend',\n      'recent_avg',\n      'recent_trend',\n      'recent_volatility',\n      'seasonal_component'\n    ];\n  }\n\n  private extractFeatures(data: any[]): number[] {\n    if (data.length === 0) return [];\n\n    const latest = data[data.length - 1];\n    const timestamp = new Date(latest.timestamp || latest.created_at);\n\n    // Time-based features\n    const hourOfDay = timestamp.getHours() / 23; // Normalize to [0, 1]\n    const dayOfWeek = timestamp.getDay() / 6;\n    const monthOfYear = timestamp.getMonth() / 11;\n    const isWeekend = (timestamp.getDay() === 0 || timestamp.getDay() === 6) ? 1 : 0;\n\n    // Statistical features from recent data\n    const values = data.map(d => d.value || d.data?.value || 0).filter(v => !isNaN(v));\n    const recentAvg = values.length > 0 ? values.reduce((sum, v) => sum + v, 0) / values.length : 0;\n    \n    // Calculate trend (simple linear regression slope)\n    const recentTrend = this.calculateTrend(values);\n    \n    // Calculate volatility (standard deviation)\n    const recentVolatility = this.calculateVolatility(values);\n    \n    // Seasonal component (simplified)\n    const seasonalComponent = Math.sin(2 * Math.PI * timestamp.getHours() / 24);\n\n    return [\n      hourOfDay,\n      dayOfWeek,\n      monthOfYear,\n      isWeekend,\n      recentAvg,\n      recentTrend,\n      recentVolatility,\n      seasonalComponent\n    ];\n  }\n\n  private normalizeFeatures(features: number[][]): number[][] {\n    if (features.length === 0) return [];\n\n    const numFeatures = features[0].length;\n    const normalized: number[][] = [];\n\n    // Calculate min/max for each feature\n    const mins = new Array(numFeatures).fill(Infinity);\n    const maxs = new Array(numFeatures).fill(-Infinity);\n\n    features.forEach(sample => {\n      sample.forEach((value, idx) => {\n        mins[idx] = Math.min(mins[idx], value);\n        maxs[idx] = Math.max(maxs[idx], value);\n      });\n    });\n\n    // Normalize each sample\n    features.forEach(sample => {\n      const normalizedSample = sample.map((value, idx) => {\n        const range = maxs[idx] - mins[idx];\n        return range === 0 ? 0 : (value - mins[idx]) / range;\n      });\n      normalized.push(normalizedSample);\n    });\n\n    return normalized;\n  }\n\n  private normalizeLabels(labels: number[]): number[] {\n    if (labels.length === 0) return [];\n\n    const min = Math.min(...labels);\n    const max = Math.max(...labels);\n    const range = max - min;\n\n    if (range === 0) return labels.map(() => 0);\n\n    return labels.map(label => (label - min) / range);\n  }\n\n  private calculateTrend(values: number[]): number {\n    if (values.length < 2) return 0;\n\n    const n = values.length;\n    const sumX = (n * (n - 1)) / 2;\n    const sumY = values.reduce((sum, v) => sum + v, 0);\n    const sumXY = values.reduce((sum, v, i) => sum + (i * v), 0);\n    const sumX2 = (n * (n - 1) * (2 * n - 1)) / 6;\n\n    const slope = (n * sumXY - sumX * sumY) / (n * sumX2 - sumX * sumX);\n    return isNaN(slope) ? 0 : slope;\n  }\n\n  private calculateVolatility(values: number[]): number {\n    if (values.length < 2) return 0;\n\n    const mean = values.reduce((sum, v) => sum + v, 0) / values.length;\n    const variance = values.reduce((sum, v) => sum + Math.pow(v - mean, 2), 0) / values.length;\n    return Math.sqrt(variance);\n  }\n\n  // Additional helper methods would continue here...\n  // (Implementation of remaining methods for space considerations)\n\n  private async getRecentDataForPrediction(metric: string, hours: number): Promise<any[]> {\n    // Implementation to fetch recent data\n    return [];\n  }\n\n  private async getMetricThreshold(metric: string): Promise<number> {\n    // Implementation to get metric thresholds\n    return 100;\n  }\n\n  private calculatePredictionConfidence(model: PredictionModel, data: any[]): number {\n    // Implementation to calculate confidence based on model accuracy and data quality\n    return model.metadata.accuracy * 0.8; // Simplified\n  }\n\n  private generateCapacityRecommendations(\n    metric: string,\n    current: number,\n    predicted: number,\n    threshold: number,\n    willExceed: boolean\n  ): string[] {\n    const recommendations: string[] = [];\n    \n    if (willExceed) {\n      recommendations.push(`${metric} is predicted to exceed threshold of ${threshold}`);\n      recommendations.push('Consider scaling infrastructure proactively');\n      recommendations.push('Review resource allocation policies');\n    } else {\n      recommendations.push(`${metric} is within normal parameters`);\n      recommendations.push('Continue monitoring for trend changes');\n    }\n\n    return recommendations;\n  }\n\n  private getTTLForTimeframe(timeframe: string): number {\n    const ttlMap = {\n      '1h': 1000 * 60 * 5,    // 5 minutes\n      '6h': 1000 * 60 * 15,   // 15 minutes\n      '24h': 1000 * 60 * 30,  // 30 minutes\n      '7d': 1000 * 60 * 60,   // 1 hour\n      '30d': 1000 * 60 * 120  // 2 hours\n    };\n    return ttlMap[timeframe] || 1000 * 60 * 10;\n  }\n\n  private estimateTimeToThreshold(data: any[], threshold: number, timeframe: string): Date | undefined {\n    // Implementation to estimate when threshold will be reached\n    const now = new Date();\n    const hours = timeframe === '1h' ? 1 : timeframe === '6h' ? 6 : 24;\n    return new Date(now.getTime() + (hours * 60 * 60 * 1000));\n  }\n\n  // Implement remaining methods...\n  private splitData(tensor: tf.Tensor2D, splitRatio: number): { xTrain: tf.Tensor2D; xValidation: tf.Tensor2D } {\n    const splitIndex = Math.floor(tensor.shape[0] * splitRatio);\n    return {\n      xTrain: tensor.slice([0, 0], [splitIndex, -1]) as tf.Tensor2D,\n      xValidation: tensor.slice([splitIndex, 0], [-1, -1]) as tf.Tensor2D\n    };\n  }\n\n  private async calculateAnomalyThresholds(trainingData: TrainingData): Promise<void> {\n    // Implementation for calculating statistical thresholds\n  }\n\n  private async calculateReconstructionErrors(model: tf.LayersModel, data: tf.Tensor2D): Promise<number[]> {\n    // Implementation for calculating reconstruction errors\n    return [];\n  }\n\n  private calculateAnomalyThreshold(errors: number[]): number {\n    // Use 95th percentile as threshold\n    const sorted = errors.sort((a, b) => a - b);\n    return sorted[Math.floor(sorted.length * 0.95)];\n  }\n\n  private createTimeWindows(dataMap: Map<string, any[]>, windowMinutes: number): any[] {\n    // Implementation for creating time windows\n    return [];\n  }\n\n  private extractAnomalyFeatures(window: any, metrics: string[]): number[] {\n    // Implementation for extracting features from time window\n    return [];\n  }\n\n  private calculateReconstructionError(original: number[], reconstructed: number[]): number {\n    let sumSquaredDiff = 0;\n    for (let i = 0; i < original.length; i++) {\n      sumSquaredDiff += Math.pow(original[i] - reconstructed[i], 2);\n    }\n    return Math.sqrt(sumSquaredDiff / original.length);\n  }\n\n  private getMetricAnomalyThreshold(metric: string): number {\n    const thresholds = {\n      'cpu_usage': 10,\n      'memory_usage': 15,\n      'app_response_time': 500\n    };\n    return thresholds[metric] || 5;\n  }\n\n  private determineSeverity(deviation: number, threshold: number): AnomalyDetection['severity'] {\n    const ratio = deviation / threshold;\n    if (ratio > 3) return 'critical';\n    if (ratio > 2) return 'high';\n    if (ratio > 1.5) return 'medium';\n    return 'low';\n  }\n\n  private generateAnomalyRecommendations(metric: string, deviation: number): string[] {\n    return [\n      `Investigate ${metric} anomaly`,\n      'Check system logs for related events',\n      'Consider scaling if pattern persists'\n    ];\n  }\n\n  private async analyzeCorrelations(): Promise<MLInsight[]> {\n    // Implementation for correlation analysis\n    return [];\n  }\n\n  private async recognizePatterns(): Promise<MLInsight[]> {\n    // Implementation for pattern recognition\n    return [];\n  }\n\n  private async forecastTrends(): Promise<MLInsight[]> {\n    // Implementation for trend forecasting\n    return [];\n  }\n\n  private async analyzeBottlenecks(): Promise<MLInsight[]> {\n    // Implementation for bottleneck analysis\n    return [];\n  }\n\n  private calculateGrowthRate(data: any[]): number {\n    if (data.length < 2) return 0;\n    \n    const first = data[0].value;\n    const last = data[data.length - 1].value;\n    const timeDiff = (new Date(data[data.length - 1].timestamp).getTime() - \n                     new Date(data[0].timestamp).getTime()) / (1000 * 60 * 60 * 24); // days\n    \n    return Math.pow(last / first, 1 / timeDiff) - 1; // Daily growth rate\n  }\n\n  private extrapolateFeatures(historicalData: any[], daysAhead: number): number[] {\n    // Implementation for feature extrapolation\n    const latest = historicalData[historicalData.length - 1];\n    const futureDate = new Date(latest.timestamp);\n    futureDate.setDate(futureDate.getDate() + daysAhead);\n    \n    return this.extractFeatures([{ ...latest, timestamp: futureDate }]);\n  }\n\n  private generateGrowthRecommendations(\n    metric: string,\n    current: number,\n    projected: number,\n    growthRate: number,\n    days: number\n  ): string[] {\n    const recommendations: string[] = [];\n    \n    const growthPercent = ((projected - current) / current) * 100;\n    \n    if (growthPercent > 50) {\n      recommendations.push(`High growth expected for ${metric}: ${growthPercent.toFixed(1)}% over ${days} days`);\n      recommendations.push('Plan for significant capacity increases');\n      recommendations.push('Consider auto-scaling solutions');\n    } else if (growthPercent > 20) {\n      recommendations.push(`Moderate growth expected for ${metric}: ${growthPercent.toFixed(1)}% over ${days} days`);\n      recommendations.push('Monitor capacity utilization closely');\n    } else {\n      recommendations.push(`Stable growth expected for ${metric}`);\n      recommendations.push('Current capacity should be sufficient');\n    }\n    \n    return recommendations;\n  }\n\n  private getMetricValueAtTime(metric: string, timestamp: Date): number | undefined {\n    // Implementation to get metric value at specific time\n    return undefined;\n  }\n}"],"names":["PredictiveAnalytics","initializeTensorFlow","tf","ready","console","log","getBackend","error","trainCapacityModel","metric","timeframeDays","isTraining","Error","startTime","performance","now","trainingData","collectTrainingData","features","length","xTrain","yTrain","xValidation","yValidation","prepareTrainingData","model","createCapacityModel","history","trainModel","accuracy","evaluateModel","predictionModel","id","Date","name","type","metadata","trainedAt","getFeatureNames","targetVariable","sampleSize","version","models","set","saveModel","lastTrainingTime","toFixed","trainAnomalyModel","metrics","join","collectMultiMetricTrainingData","calculateAnomalyThresholds","createAnomalyModel","xTensor","tensor2d","splitData","fit","epochs","batchSize","validationData","shuffle","callbacks","onEpochEnd","epoch","logs","loss","val_loss","reconstructionErrors","calculateReconstructionErrors","threshold","calculateAnomalyThreshold","predictCapacity","timeframe","cacheKey","cached","cache","get","findBestModel","recentData","getRecentDataForPrediction","extractFeatures","inputTensor","prediction","predict","predictedValue","data","currentValue","value","confidence","calculatePredictionConfidence","getMetricThreshold","willExceedThreshold","timeToThreshold","estimateTimeToThreshold","undefined","recommendations","generateCapacityRecommendations","result","ttl","getTTLForTimeframe","dispose","detectAnomalies","anomalies","recentDataMap","Map","timeWindows","createTimeWindows","window","extractAnomalyFeatures","reconstruction","reconstructedValues","reconstructionError","calculateReconstructionError","Array","from","anomalyThresholds","i","expectedValue","deviation","Math","abs","getMetricAnomalyThreshold","anomaly","random","toString","substr","severity","determineSeverity","probability","min","timestamp","context","allMetrics","Object","fromEntries","map","m","idx","generateAnomalyRecommendations","push","generateMLInsights","insights","correlationInsights","analyzeCorrelations","patternInsights","recognizePatterns","trendInsights","forecastTrends","bottleneckInsights","analyzeBottlenecks","getGrowthProjections","projectionDays","historicalData","growthRate","calculateGrowthRate","projectionDates","projectedValues","date","setDate","getDate","extrapolateFeatures","projectedValue","generateGrowthRecommendations","current","projected","autoRetrainModels","shouldRetrain","getTime","keyMetrics","message","loadExistingModels","endTime","events","eventStore","getEvents","start_time","end_time","limit","labels","timestamps","event","featureVector","eventCount","point","getMetricValueAtTime","filter","v","isNaN","normalizedFeatures","normalizeFeatures","normalizedLabels","normalizeLabels","splitIndex","floor","slice","inputShape","sequential","layers","dense","units","activation","kernelRegularizer","regularizers","l2","dropout","rate","compile","optimizer","train","adam","evaluation","evaluate","modelPath","save","target","candidates","values","includes","sort","a","b","latest","created_at","hourOfDay","getHours","dayOfWeek","getDay","monthOfYear","getMonth","isWeekend","d","recentAvg","reduce","sum","recentTrend","calculateTrend","recentVolatility","calculateVolatility","seasonalComponent","sin","PI","numFeatures","normalized","mins","fill","Infinity","maxs","forEach","sample","max","normalizedSample","range","label","n","sumX","sumY","sumXY","sumX2","slope","mean","variance","pow","sqrt","hours","predicted","willExceed","ttlMap","tensor","splitRatio","shape","errors","sorted","dataMap","windowMinutes","original","reconstructed","sumSquaredDiff","thresholds","ratio","first","last","timeDiff","daysAhead","futureDate","days","growthPercent","analyticsEngine","performanceMonitor","LRUCache","EventStore","getInstance","AnalyticsEngine","PerformanceMonitor"],"mappings":";;;;+BAmEaA;;;eAAAA;;;kEAnEO;4BACuB;iCACX;oCACG;0BACV;4BACG;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA8DrB,MAAMA;IA4BX;;GAEC,GACD,MAAcC,uBAAsC;QAClD,IAAI;YACF,MAAMC,UAAGC,KAAK;YACdC,QAAQC,GAAG,CAAC,sCAAsCH,UAAGI,UAAU;QACjE,EAAE,OAAOC,OAAO;YACdH,QAAQG,KAAK,CAAC,uCAAuCA;QACvD;IACF;IAEA;;GAEC,GACD,MAAaC,mBACXC,MAAc,EACdC,gBAAwB,EAAE,EACA;QAC1B,IAAI,IAAI,CAACC,UAAU,EAAE;YACnB,MAAM,IAAIC,MAAM;QAClB;QAEA,IAAI,CAACD,UAAU,GAAG;QAClB,MAAME,YAAYC,uBAAW,CAACC,GAAG;QAEjC,IAAI;YACFX,QAAQC,GAAG,CAAC,CAAC,uCAAuC,EAAEI,OAAO,GAAG,CAAC;YAEjE,wBAAwB;YACxB,MAAMO,eAAe,MAAM,IAAI,CAACC,mBAAmB,CAACR,QAAQC;YAE5D,IAAIM,aAAaE,QAAQ,CAACC,MAAM,GAAG,IAAI;gBACrC,MAAM,IAAIP,MAAM,CAAC,4BAA4B,EAAEI,aAAaE,QAAQ,CAACC,MAAM,CAAC,QAAQ,CAAC;YACvF;YAEA,uBAAuB;YACvB,MAAM,EAAEC,MAAM,EAAEC,MAAM,EAAEC,WAAW,EAAEC,WAAW,EAAE,GAAG,IAAI,CAACC,mBAAmB,CAACR;YAE9E,6BAA6B;YAC7B,MAAMS,QAAQ,IAAI,CAACC,mBAAmB,CAACV,aAAaE,QAAQ,CAAC,EAAE,CAACC,MAAM;YAEtE,cAAc;YACd,MAAMQ,UAAU,MAAM,IAAI,CAACC,UAAU,CAACH,OAAOL,QAAQC,QAAQC,aAAaC;YAE1E,iBAAiB;YACjB,MAAMM,WAAW,MAAM,IAAI,CAACC,aAAa,CAACL,OAAOH,aAAaC;YAE9D,iCAAiC;YACjC,MAAMQ,kBAAmC;gBACvCC,IAAI,CAAC,SAAS,EAAEvB,OAAO,CAAC,EAAEwB,KAAKlB,GAAG,IAAI;gBACtCmB,MAAM,CAAC,wBAAwB,EAAEzB,QAAQ;gBACzC0B,MAAM;gBACNV;gBACAW,UAAU;oBACRC,WAAW,IAAIJ;oBACfJ;oBACAX,UAAU,IAAI,CAACoB,eAAe;oBAC9BC,gBAAgB9B;oBAChB+B,YAAYxB,aAAaE,QAAQ,CAACC,MAAM;oBACxCsB,SAAS;gBACX;YACF;YAEA,cAAc;YACd,IAAI,CAACC,MAAM,CAACC,GAAG,CAACZ,gBAAgBC,EAAE,EAAED;YAEpC,qBAAqB;YACrB,MAAM,IAAI,CAACa,SAAS,CAACb;YAErB,IAAI,CAACc,gBAAgB,GAAG,IAAIZ;YAC5B7B,QAAQC,GAAG,CAAC,CAAC,0BAA0B,EAAE,AAACS,CAAAA,uBAAW,CAACC,GAAG,KAAKF,SAAQ,EAAGiC,OAAO,CAAC,GAAG,kBAAkB,EAAEjB,SAASiB,OAAO,CAAC,IAAI;YAE7H,OAAOf;QAET,SAAU;YACR,IAAI,CAACpB,UAAU,GAAG;QACpB;IACF;IAEA;;GAEC,GACD,MAAaoC,kBACXC,OAAiB,EACjBtC,gBAAwB,EAAE,EACA;QAC1B,IAAI,IAAI,CAACC,UAAU,EAAE;YACnB,MAAM,IAAIC,MAAM;QAClB;QAEA,IAAI,CAACD,UAAU,GAAG;QAClB,MAAME,YAAYC,uBAAW,CAACC,GAAG;QAEjC,IAAI;YACFX,QAAQC,GAAG,CAAC,CAAC,8CAA8C,EAAE2C,QAAQC,IAAI,CAAC,MAAM,GAAG,CAAC;YAEpF,qCAAqC;YACrC,MAAMjC,eAAe,MAAM,IAAI,CAACkC,8BAA8B,CAACF,SAAStC;YAExE,IAAIM,aAAaE,QAAQ,CAACC,MAAM,GAAG,KAAK;gBACtC,MAAM,IAAIP,MAAM,CAAC,4BAA4B,EAAEI,aAAaE,QAAQ,CAACC,MAAM,CAAC,QAAQ,CAAC;YACvF;YAEA,mDAAmD;YACnD,MAAM,IAAI,CAACgC,0BAA0B,CAACnC;YAEtC,2CAA2C;YAC3C,MAAMS,QAAQ,IAAI,CAAC2B,kBAAkB,CAACpC,aAAaE,QAAQ,CAAC,EAAE,CAACC,MAAM;YAErE,4DAA4D;YAC5D,MAAMkC,UAAUnD,UAAGoD,QAAQ,CAACtC,aAAaE,QAAQ;YACjD,MAAM,EAAEE,MAAM,EAAEE,WAAW,EAAE,GAAG,IAAI,CAACiC,SAAS,CAACF,SAAS;YAExD,oBAAoB;YACpB,MAAM1B,UAAU,MAAMF,MAAM+B,GAAG,CAACpC,QAAQA,QAAQ;gBAC9CqC,QAAQ;gBACRC,WAAW;gBACXC,gBAAgB;oBAACrC;oBAAaA;iBAAY;gBAC1CsC,SAAS;gBACTC,WAAW;oBACTC,YAAY,CAACC,OAAOC;wBAClB,IAAID,QAAQ,OAAO,GAAG;4BACpB3D,QAAQC,GAAG,CAAC,CAAC,MAAM,EAAE0D,MAAM,SAAS,EAAEC,MAAMC,MAAMnB,QAAQ,GAAG,aAAa,EAAEkB,MAAME,UAAUpB,QAAQ,IAAI;wBAC1G;oBACF;gBACF;YACF;YAEA,qCAAqC;YACrC,MAAMqB,uBAAuB,MAAM,IAAI,CAACC,6BAA6B,CAAC3C,OAAOH;YAC7E,MAAM+C,YAAY,IAAI,CAACC,yBAAyB,CAACH;YAEjD,MAAMpC,kBAAmC;gBACvCC,IAAI,CAAC,QAAQ,EAAEgB,QAAQC,IAAI,CAAC,KAAK,CAAC,EAAEhB,KAAKlB,GAAG,IAAI;gBAChDmB,MAAM,CAAC,sBAAsB,EAAEc,QAAQC,IAAI,CAAC,OAAO;gBACnDd,MAAM;gBACNV;gBACAW,UAAU;oBACRC,WAAW,IAAIJ;oBACfJ,UAAUwC;oBACVnD,UAAU8B;oBACVT,gBAAgB;oBAChBC,YAAYxB,aAAaE,QAAQ,CAACC,MAAM;oBACxCsB,SAAS;gBACX;YACF;YAEA,IAAI,CAACC,MAAM,CAACC,GAAG,CAACZ,gBAAgBC,EAAE,EAAED;YACpC,MAAM,IAAI,CAACa,SAAS,CAACb;YAErB,IAAI,CAACc,gBAAgB,GAAG,IAAIZ;YAC5B7B,QAAQC,GAAG,CAAC,CAAC,yBAAyB,EAAE,AAACS,CAAAA,uBAAW,CAACC,GAAG,KAAKF,SAAQ,EAAGiC,OAAO,CAAC,GAAG,EAAE,CAAC;YAEtF,OAAOf;QAET,SAAU;YACR,IAAI,CAACpB,UAAU,GAAG;QACpB;IACF;IAEA;;GAEC,GACD,MAAa4D,gBACX9D,MAAc,EACd+D,YAA6C,KAAK,EACrB;QAC7B,MAAMC,WAAW,CAAC,oBAAoB,EAAEhE,OAAO,CAAC,EAAE+D,WAAW;QAC7D,MAAME,SAAS,IAAI,CAACC,KAAK,CAACC,GAAG,CAACH;QAE9B,IAAIC,QAAQ;YACV,OAAOA;QACT;QAEA,MAAMjD,QAAQ,IAAI,CAACoD,aAAa,CAAC,YAAYpE;QAC7C,IAAI,CAACgB,OAAO;YACV,MAAM,IAAIb,MAAM,CAAC,wCAAwC,EAAEH,QAAQ;QACrE;QAEA,iCAAiC;QACjC,MAAMqE,aAAa,MAAM,IAAI,CAACC,0BAA0B,CAACtE,QAAQ,KAAK,gBAAgB;QAEtF,IAAIqE,WAAW3D,MAAM,KAAK,GAAG;YAC3B,MAAM,IAAIP,MAAM,CAAC,qCAAqC,EAAEH,QAAQ;QAClE;QAEA,yBAAyB;QACzB,MAAMS,WAAW,IAAI,CAAC8D,eAAe,CAACF;QACtC,MAAMG,cAAc/E,UAAGoD,QAAQ,CAAC;YAACpC;SAAS;QAE1C,kBAAkB;QAClB,MAAMgE,aAAazD,MAAMA,KAAK,CAAC0D,OAAO,CAACF;QACvC,MAAMG,iBAAiB,AAAC,CAAA,MAAMF,WAAWG,IAAI,EAAC,CAAE,CAAC,EAAE;QAEnD,oBAAoB;QACpB,MAAMC,eAAeR,UAAU,CAACA,WAAW3D,MAAM,GAAG,EAAE,CAACoE,KAAK;QAE5D,iEAAiE;QACjE,MAAMC,aAAa,IAAI,CAACC,6BAA6B,CAAChE,OAAOqD;QAE7D,gCAAgC;QAChC,MAAMT,YAAY,MAAM,IAAI,CAACqB,kBAAkB,CAACjF;QAEhD,0CAA0C;QAC1C,MAAMkF,sBAAsBP,iBAAiBf;QAE7C,2CAA2C;QAC3C,MAAMuB,kBAAkBD,sBACpB,IAAI,CAACE,uBAAuB,CAACf,YAAYT,WAAWG,aACpDsB;QAEJ,2BAA2B;QAC3B,MAAMC,kBAAkB,IAAI,CAACC,+BAA+B,CAC1DvF,QACA6E,cACAF,gBACAf,WACAsB;QAGF,MAAMM,SAA6B;YACjCxF;YACA+D;YACAc;YACAF;YACAI;YACAnB;YACAsB;YACAC;YACAG;QACF;QAEA,eAAe;QACf,IAAI,CAACpB,KAAK,CAAChC,GAAG,CAAC8B,UAAUwB,QAAQ;YAAEC,KAAK,IAAI,CAACC,kBAAkB,CAAC3B;QAAW;QAE3E,kBAAkB;QAClBS,YAAYmB,OAAO;QACnBlB,WAAWkB,OAAO;QAElB,OAAOH;IACT;IAEA;;GAEC,GACD,MAAaI,gBACXrD,UAAoB;QAAC;QAAa;QAAgB;KAAoB,EACzC;QAC7B,MAAMyB,WAAW,CAAC,kBAAkB,EAAEzB,QAAQC,IAAI,CAAC,MAAM;QACzD,MAAMyB,SAAS,IAAI,CAACC,KAAK,CAACC,GAAG,CAACH;QAE9B,IAAIC,QAAQ;YACV,OAAOA;QACT;QAEA,MAAMjD,QAAQ,IAAI,CAACoD,aAAa,CAAC,WAAW7B,QAAQC,IAAI,CAAC;QACzD,IAAI,CAACxB,OAAO;YACV,MAAM,IAAIb,MAAM,CAAC,wCAAwC,EAAEoC,QAAQC,IAAI,CAAC,OAAO;QACjF;QAEA,MAAMqD,YAAgC,EAAE;QAExC,kCAAkC;QAClC,MAAMC,gBAAgB,IAAIC;QAC1B,KAAK,MAAM/F,UAAUuC,QAAS;YAC5B,MAAMqC,OAAO,MAAM,IAAI,CAACN,0BAA0B,CAACtE,QAAQ,IAAI,YAAY;YAC3E8F,cAAc5D,GAAG,CAAClC,QAAQ4E;QAC5B;QAEA,2BAA2B;QAC3B,MAAMoB,cAAc,IAAI,CAACC,iBAAiB,CAACH,eAAe,IAAI,mBAAmB;QAEjF,KAAK,MAAMI,UAAUF,YAAa;YAChC,wCAAwC;YACxC,MAAMvF,WAAW,IAAI,CAAC0F,sBAAsB,CAACD,QAAQ3D;YAErD,IAAI9B,SAASC,MAAM,KAAK,GAAG;YAE3B,kCAAkC;YAClC,MAAM8D,cAAc/E,UAAGoD,QAAQ,CAAC;gBAACpC;aAAS;YAC1C,MAAM2F,iBAAiBpF,MAAMA,KAAK,CAAC0D,OAAO,CAACF;YAC3C,MAAM6B,sBAAsB,MAAMD,eAAexB,IAAI;YAErD,iCAAiC;YACjC,MAAM0B,sBAAsB,IAAI,CAACC,4BAA4B,CAAC9F,UAAU+F,MAAMC,IAAI,CAACJ;YAEnF,0BAA0B;YAC1B,MAAMzC,YAAY,IAAI,CAAC8C,iBAAiB,CAACvC,GAAG,CAAC5B,QAAQC,IAAI,CAAC,OAAOoB,aAAa;YAE9E,IAAI0C,sBAAsB1C,WAAW;gBACnC,wCAAwC;gBACxC,IAAK,IAAI+C,IAAI,GAAGA,IAAIpE,QAAQ7B,MAAM,EAAEiG,IAAK;oBACvC,MAAM3G,SAASuC,OAAO,CAACoE,EAAE;oBACzB,MAAM9B,eAAepE,QAAQ,CAACkG,EAAE;oBAChC,MAAMC,gBAAgBP,mBAAmB,CAACM,EAAE;oBAC5C,MAAME,YAAYC,KAAKC,GAAG,CAAClC,eAAe+B;oBAE1C,IAAIC,YAAY,IAAI,CAACG,yBAAyB,CAAChH,SAAS;wBACtD,MAAMiH,UAA4B;4BAChC1F,IAAI,CAAC,QAAQ,EAAEvB,OAAO,CAAC,EAAEwB,KAAKlB,GAAG,GAAG,CAAC,EAAEwG,KAAKI,MAAM,GAAGC,QAAQ,CAAC,IAAIC,MAAM,CAAC,GAAG,IAAI;4BAChFpH;4BACA8E,OAAOD;4BACP+B;4BACAC;4BACAQ,UAAU,IAAI,CAACC,iBAAiB,CAACT,WAAW,IAAI,CAACG,yBAAyB,CAAChH;4BAC3EuH,aAAaT,KAAKU,GAAG,CAAClB,sBAAsB1C,WAAW;4BACvD6D,WAAWvB,OAAOuB,SAAS;4BAC3BC,SAAS;gCACPpB;gCACA1C;gCACA+D,YAAYC,OAAOC,WAAW,CAC5BtF,QAAQuF,GAAG,CAAC,CAACC,GAAGC,MAAQ;wCAACD;wCAAGtH,QAAQ,CAACuH,IAAI;qCAAC;4BAE9C;4BACA1C,iBAAiB,IAAI,CAAC2C,8BAA8B,CAACjI,QAAQ6G;wBAC/D;wBAEAhB,UAAUqC,IAAI,CAACjB;oBACjB;gBACF;YACF;YAEA,kBAAkB;YAClBzC,YAAYmB,OAAO;YACnBS,eAAeT,OAAO;QACxB;QAEA,iCAAiC;QACjC,IAAI,CAACzB,KAAK,CAAChC,GAAG,CAAC8B,UAAU6B,WAAW;YAAEJ,KAAK,OAAO,KAAK;QAAE,IAAI,YAAY;QAEzE,OAAOI;IACT;IAEA;;GAEC,GACD,MAAasC,qBAA2C;QACtD,MAAMC,WAAwB,EAAE;QAEhC,IAAI;YACF,uBAAuB;YACvB,MAAMC,sBAAsB,MAAM,IAAI,CAACC,mBAAmB;YAC1DF,SAASF,IAAI,IAAIG;YAEjB,sBAAsB;YACtB,MAAME,kBAAkB,MAAM,IAAI,CAACC,iBAAiB;YACpDJ,SAASF,IAAI,IAAIK;YAEjB,oBAAoB;YACpB,MAAME,gBAAgB,MAAM,IAAI,CAACC,cAAc;YAC/CN,SAASF,IAAI,IAAIO;YAEjB,kCAAkC;YAClC,MAAME,qBAAqB,MAAM,IAAI,CAACC,kBAAkB;YACxDR,SAASF,IAAI,IAAIS;QAEnB,EAAE,OAAO7I,OAAO;YACdH,QAAQG,KAAK,CAAC,iCAAiCA;QACjD;QAEA,OAAOsI;IACT;IAEA;;GAEC,GACD,MAAaS,qBACX7I,MAAc,EACd8I,iBAAyB,EAAE,EAS1B;QACD,MAAM9H,QAAQ,IAAI,CAACoD,aAAa,CAAC,YAAYpE;QAC7C,IAAI,CAACgB,OAAO;YACV,MAAM,IAAIb,MAAM,CAAC,wCAAwC,EAAEH,QAAQ;QACrE;QAEA,yCAAyC;QACzC,MAAM+I,iBAAiB,MAAM,IAAI,CAACzE,0BAA0B,CAACtE,QAAQ8I,iBAAiB;QAEtF,IAAIC,eAAerI,MAAM,KAAK,GAAG;YAC/B,MAAM,IAAIP,MAAM,CAAC,yCAAyC,EAAEH,QAAQ;QACtE;QAEA,wBAAwB;QACxB,MAAMgJ,aAAa,IAAI,CAACC,mBAAmB,CAACF;QAE5C,uBAAuB;QACvB,MAAMG,kBAA0B,EAAE;QAClC,MAAMC,kBAA4B,EAAE;QACpC,MAAMtE,eAAekE,cAAc,CAACA,eAAerI,MAAM,GAAG,EAAE,CAACoE,KAAK;QAEpE,IAAK,IAAI6B,IAAI,GAAGA,KAAKmC,gBAAgBnC,IAAK;YACxC,MAAMyC,OAAO,IAAI5H;YACjB4H,KAAKC,OAAO,CAACD,KAAKE,OAAO,KAAK3C;YAC9BuC,gBAAgBhB,IAAI,CAACkB;YAErB,oCAAoC;YACpC,MAAM3I,WAAW,IAAI,CAAC8I,mBAAmB,CAACR,gBAAgBpC;YAC1D,MAAMnC,cAAc/E,UAAGoD,QAAQ,CAAC;gBAACpC;aAAS;YAC1C,MAAMgE,aAAazD,MAAMA,KAAK,CAAC0D,OAAO,CAACF;YACvC,MAAMG,iBAAiB,AAAC,CAAA,MAAMF,WAAWG,IAAI,EAAC,CAAE,CAAC,EAAE;YAEnDuE,gBAAgBjB,IAAI,CAACvD;YAErB,UAAU;YACVH,YAAYmB,OAAO;YACnBlB,WAAWkB,OAAO;QACpB;QAEA,MAAM6D,iBAAiBL,eAAe,CAACA,gBAAgBzI,MAAM,GAAG,EAAE;QAClE,MAAMqE,aAAa,IAAI,CAACC,6BAA6B,CAAChE,OAAO+H;QAE7D,gDAAgD;QAChD,MAAMzD,kBAAkB,IAAI,CAACmE,6BAA6B,CACxDzJ,QACA6E,cACA2E,gBACAR,YACAF;QAGF,OAAO;YACLY,SAAS7E;YACT8E,WAAWH;YACXR;YACAE;YACAC;YACApE;YACAO;QACF;IACF;IAEA;;GAEC,GACD,MAAasE,oBAAmC;QAC9C,IAAI,IAAI,CAAC1J,UAAU,EAAE;YACnBP,QAAQC,GAAG,CAAC;YACZ;QACF;QAEA,MAAMU,MAAM,IAAIkB;QAChB,MAAMqI,gBAAgB,CAAC,IAAI,CAACzH,gBAAgB,IAC1C,AAAC9B,IAAIwJ,OAAO,KAAK,IAAI,CAAC1H,gBAAgB,CAAC0H,OAAO,KAAO,IAAI,KAAK,KAAK,KAAK,MAAO,SAAS;QAE1F,IAAI,CAACD,eAAe;YAClB;QACF;QAEAlK,QAAQC,GAAG,CAAC;QAEZ,IAAI;YACF,0CAA0C;YAC1C,MAAMmK,aAAa;gBAAC;gBAAa;gBAAgB;gBAAqB;aAAiB;YAEvF,KAAK,MAAM/J,UAAU+J,WAAY;gBAC/B,IAAI;oBACF,MAAM,IAAI,CAAChK,kBAAkB,CAACC,QAAQ;oBACtCL,QAAQC,GAAG,CAAC,CAAC,0CAA0C,EAAEI,QAAQ;gBACnE,EAAE,OAAOF,OAAO;oBACdH,QAAQG,KAAK,CAAC,CAAC,qCAAqC,EAAEE,OAAO,CAAC,CAAC,EAAEF,MAAMkK,OAAO;gBAChF;YACF;YAEA,kCAAkC;YAClC,IAAI;gBACF,MAAM,IAAI,CAAC1H,iBAAiB,CAACyH,YAAY;gBACzCpK,QAAQC,GAAG,CAAC;YACd,EAAE,OAAOE,OAAO;gBACdH,QAAQG,KAAK,CAAC,8CAA8CA,MAAMkK,OAAO;YAC3E;QAEF,EAAE,OAAOlK,OAAO;YACdH,QAAQG,KAAK,CAAC,8BAA8BA;QAC9C;IACF;IAEA,4BAA4B;IAE5B,MAAcmK,qBAAoC;QAChD,gDAAgD;QAChDtK,QAAQC,GAAG,CAAC;IACd;IAEA,MAAcY,oBAAoBR,MAAc,EAAEC,aAAqB,EAAyB;QAC9F,MAAMiK,UAAU,IAAI1I;QACpB,MAAMpB,YAAY,IAAIoB,KAAK0I,QAAQJ,OAAO,KAAM7J,gBAAgB,KAAK,KAAK,KAAK;QAE/E,MAAMkK,SAAS,MAAM,IAAI,CAACC,UAAU,CAACC,SAAS,CAAC;YAC7CC,YAAYlK;YACZmK,UAAUL;YACVM,OAAO;QACT;QAEA,4CAA4C;QAC5C,MAAM/J,WAAuB,EAAE;QAC/B,MAAMgK,SAAmB,EAAE;QAC3B,MAAMC,aAAqB,EAAE;QAE7B,yCAAyC;QACzC,KAAK,MAAMC,SAASR,OAAQ;YAC1B,IAAIQ,MAAM/F,IAAI,CAAC5E,OAAO,KAAKqF,WAAW;gBACpC,MAAMuF,gBAAgB,IAAI,CAACrG,eAAe,CAAC;oBAACoG;iBAAM;gBAClD,IAAIC,cAAclK,MAAM,GAAG,GAAG;oBAC5BD,SAASyH,IAAI,CAAC0C;oBACdH,OAAOvC,IAAI,CAACyC,MAAM/F,IAAI,CAAC5E,OAAO;oBAC9B0K,WAAWxC,IAAI,CAAC,IAAI1G,KAAKmJ,MAAMlD,SAAS;gBAC1C;YACF;QACF;QAEA,OAAO;YACLhH;YACAgK;YACAC;YACA/I,UAAU;gBAAE3B;gBAAQC;gBAAe4K,YAAYV,OAAOzJ,MAAM;YAAC;QAC/D;IACF;IAEA,MAAc+B,+BAA+BF,OAAiB,EAAEtC,aAAqB,EAAyB;QAC5G,MAAMiK,UAAU,IAAI1I;QACpB,MAAMpB,YAAY,IAAIoB,KAAK0I,QAAQJ,OAAO,KAAM7J,gBAAgB,KAAK,KAAK,KAAK;QAE/E,MAAMQ,WAAuB,EAAE;QAC/B,MAAMgK,SAAmB,EAAE;QAC3B,MAAMC,aAAqB,EAAE;QAE7B,2BAA2B;QAC3B,KAAK,MAAM1K,UAAUuC,QAAS;YAC5B,MAAMqC,OAAO,MAAM,IAAI,CAACN,0BAA0B,CAACtE,QAAQC,gBAAgB;YAE3E,KAAK,MAAM6K,SAASlG,KAAM;gBACxB,MAAMgG,gBAAgBrI,QAAQuF,GAAG,CAACC,CAAAA,IAChCA,MAAM/H,SAAS8K,MAAMhG,KAAK,GAAG,IAAI,CAACiG,oBAAoB,CAAChD,GAAG+C,MAAMrD,SAAS,GACzEuD,MAAM,CAACC,CAAAA,IAAKA,MAAM5F,aAAa,CAAC6F,MAAMD;gBAExC,IAAIL,cAAclK,MAAM,KAAK6B,QAAQ7B,MAAM,EAAE;oBAC3CD,SAASyH,IAAI,CAAC0C;oBACdH,OAAOvC,IAAI,CAAC,IAAI,4BAA4B;oBAC5CwC,WAAWxC,IAAI,CAAC4C,MAAMrD,SAAS;gBACjC;YACF;QACF;QAEA,OAAO;YACLhH;YACAgK;YACAC;YACA/I,UAAU;gBAAEY;gBAAStC;YAAc;QACrC;IACF;IAEQc,oBAAoBR,YAA0B,EAKpD;QACA,qBAAqB;QACrB,MAAM4K,qBAAqB,IAAI,CAACC,iBAAiB,CAAC7K,aAAaE,QAAQ;QACvE,MAAM4K,mBAAmB,IAAI,CAACC,eAAe,CAAC/K,aAAakK,MAAM;QAEjE,aAAa;QACb,MAAMc,aAAazE,KAAK0E,KAAK,CAACL,mBAAmBzK,MAAM,GAAG;QAE1D,MAAMC,SAASlB,UAAGoD,QAAQ,CAACsI,mBAAmBM,KAAK,CAAC,GAAGF;QACvD,MAAM3K,SAASnB,UAAGoD,QAAQ,CAACwI,iBAAiBI,KAAK,CAAC,GAAGF,aAAa;YAACA;YAAY;SAAE;QACjF,MAAM1K,cAAcpB,UAAGoD,QAAQ,CAACsI,mBAAmBM,KAAK,CAACF;QACzD,MAAMzK,cAAcrB,UAAGoD,QAAQ,CAACwI,iBAAiBI,KAAK,CAACF,aAAa;YAACF,iBAAiB3K,MAAM,GAAG6K;YAAY;SAAE;QAE7G,OAAO;YAAE5K;YAAQC;YAAQC;YAAaC;QAAY;IACpD;IAEQG,oBAAoByK,UAAkB,EAAkB;QAC9D,MAAM1K,QAAQvB,UAAGkM,UAAU,CAAC;YAC1BC,QAAQ;gBACNnM,UAAGmM,MAAM,CAACC,KAAK,CAAC;oBACdH,YAAY;wBAACA;qBAAW;oBACxBI,OAAO;oBACPC,YAAY;oBACZC,mBAAmBvM,UAAGwM,YAAY,CAACC,EAAE,CAAC;wBAAEA,IAAI;oBAAK;gBACnD;gBACAzM,UAAGmM,MAAM,CAACO,OAAO,CAAC;oBAAEC,MAAM;gBAAI;gBAC9B3M,UAAGmM,MAAM,CAACC,KAAK,CAAC;oBACdC,OAAO;oBACPC,YAAY;oBACZC,mBAAmBvM,UAAGwM,YAAY,CAACC,EAAE,CAAC;wBAAEA,IAAI;oBAAK;gBACnD;gBACAzM,UAAGmM,MAAM,CAACO,OAAO,CAAC;oBAAEC,MAAM;gBAAI;gBAC9B3M,UAAGmM,MAAM,CAACC,KAAK,CAAC;oBACdC,OAAO;oBACPC,YAAY;gBACd;gBACAtM,UAAGmM,MAAM,CAACC,KAAK,CAAC;oBACdC,OAAO;oBACPC,YAAY;gBACd;aACD;QACH;QAEA/K,MAAMqL,OAAO,CAAC;YACZC,WAAW7M,UAAG8M,KAAK,CAACC,IAAI,CAAC;YACzBhJ,MAAM;YACNjB,SAAS;gBAAC;aAAM;QAClB;QAEA,OAAOvB;IACT;IAEQ2B,mBAAmB+I,UAAkB,EAAkB;QAC7D,oCAAoC;QACpC,MAAM1K,QAAQvB,UAAGkM,UAAU,CAAC;YAC1BC,QAAQ;gBACN,UAAU;gBACVnM,UAAGmM,MAAM,CAACC,KAAK,CAAC;oBACdH,YAAY;wBAACA;qBAAW;oBACxBI,OAAO;oBACPC,YAAY;gBACd;gBACAtM,UAAGmM,MAAM,CAACC,KAAK,CAAC;oBACdC,OAAO;oBACPC,YAAY;gBACd;gBACAtM,UAAGmM,MAAM,CAACC,KAAK,CAAC;oBACdC,OAAO;oBACPC,YAAY;gBACd;gBACA,UAAU;gBACVtM,UAAGmM,MAAM,CAACC,KAAK,CAAC;oBACdC,OAAO;oBACPC,YAAY;gBACd;gBACAtM,UAAGmM,MAAM,CAACC,KAAK,CAAC;oBACdC,OAAO;oBACPC,YAAY;gBACd;gBACAtM,UAAGmM,MAAM,CAACC,KAAK,CAAC;oBACdC,OAAOJ;oBACPK,YAAY;gBACd;aACD;QACH;QAEA/K,MAAMqL,OAAO,CAAC;YACZC,WAAW7M,UAAG8M,KAAK,CAACC,IAAI,CAAC;YACzBhJ,MAAM;QACR;QAEA,OAAOxC;IACT;IAEA,MAAcG,WACZH,KAAqB,EACrBL,MAAmB,EACnBC,MAAmB,EACnBC,WAAwB,EACxBC,WAAwB,EACH;QACrB,OAAO,MAAME,MAAM+B,GAAG,CAACpC,QAAQC,QAAQ;YACrCoC,QAAQ;YACRC,WAAW;YACXC,gBAAgB;gBAACrC;gBAAaC;aAAY;YAC1CqC,SAAS;YACTC,WAAW;gBACTC,YAAY,CAACC,OAAOC;oBAClB,IAAID,QAAQ,OAAO,GAAG;wBACpB3D,QAAQC,GAAG,CAAC,CAAC,MAAM,EAAE0D,MAAM,SAAS,EAAEC,MAAMC,MAAMnB,QAAQ,GAAG,aAAa,EAAEkB,MAAME,UAAUpB,QAAQ,IAAI;oBAC1G;gBACF;YACF;QACF;IACF;IAEA,MAAchB,cACZL,KAAqB,EACrBH,WAAwB,EACxBC,WAAwB,EACP;QACjB,MAAM2L,aAAazL,MAAM0L,QAAQ,CAAC7L,aAAaC;QAC/C,MAAM0C,OAAO,MAAMiJ,UAAU,CAAC,EAAE,CAAC7H,IAAI;QACrC,OAAO,IAAIpB,IAAI,CAAC,EAAE,EAAE,uCAAuC;IAC7D;IAEA,MAAcrB,UAAUb,eAAgC,EAAiB;QACvE,IAAI;YACF,MAAMqL,YAAY,CAAC,gBAAgB,EAAErL,gBAAgBC,EAAE,EAAE;YACzD,MAAMD,gBAAgBN,KAAK,CAAC4L,IAAI,CAACD;YACjChN,QAAQC,GAAG,CAAC,CAAC,eAAe,EAAE+M,WAAW;QAC3C,EAAE,OAAO7M,OAAO;YACdH,QAAQG,KAAK,CAAC,yBAAyBA;QACzC;IACF;IAEQsE,cAAc1C,IAA6B,EAAEmL,MAAc,EAA0B;QAC3F,MAAMC,aAAatG,MAAMC,IAAI,CAAC,IAAI,CAACxE,MAAM,CAAC8K,MAAM,IAC7C/B,MAAM,CAAChK,CAAAA,QAASA,MAAMU,IAAI,KAAKA,QAC7BV,CAAAA,MAAMW,QAAQ,CAACG,cAAc,KAAK+K,UAClC7L,MAAMW,QAAQ,CAAClB,QAAQ,CAACuM,QAAQ,CAACH,OAAM,GACzCI,IAAI,CAAC,CAACC,GAAGC,IAAMA,EAAExL,QAAQ,CAACP,QAAQ,GAAG8L,EAAEvL,QAAQ,CAACP,QAAQ;QAE3D,OAAO0L,UAAU,CAAC,EAAE,IAAI;IAC1B;IAEQjL,kBAA4B;QAClC,OAAO;YACL;YACA;YACA;YACA;YACA;YACA;YACA;YACA;SACD;IACH;IAEQ0C,gBAAgBK,IAAW,EAAY;QAC7C,IAAIA,KAAKlE,MAAM,KAAK,GAAG,OAAO,EAAE;QAEhC,MAAM0M,SAASxI,IAAI,CAACA,KAAKlE,MAAM,GAAG,EAAE;QACpC,MAAM+G,YAAY,IAAIjG,KAAK4L,OAAO3F,SAAS,IAAI2F,OAAOC,UAAU;QAEhE,sBAAsB;QACtB,MAAMC,YAAY7F,UAAU8F,QAAQ,KAAK,IAAI,sBAAsB;QACnE,MAAMC,YAAY/F,UAAUgG,MAAM,KAAK;QACvC,MAAMC,cAAcjG,UAAUkG,QAAQ,KAAK;QAC3C,MAAMC,YAAY,AAACnG,UAAUgG,MAAM,OAAO,KAAKhG,UAAUgG,MAAM,OAAO,IAAK,IAAI;QAE/E,wCAAwC;QACxC,MAAMV,SAASnI,KAAKkD,GAAG,CAAC+F,CAAAA,IAAKA,EAAE/I,KAAK,IAAI+I,EAAEjJ,IAAI,EAAEE,SAAS,GAAGkG,MAAM,CAACC,CAAAA,IAAK,CAACC,MAAMD;QAC/E,MAAM6C,YAAYf,OAAOrM,MAAM,GAAG,IAAIqM,OAAOgB,MAAM,CAAC,CAACC,KAAK/C,IAAM+C,MAAM/C,GAAG,KAAK8B,OAAOrM,MAAM,GAAG;QAE9F,mDAAmD;QACnD,MAAMuN,cAAc,IAAI,CAACC,cAAc,CAACnB;QAExC,4CAA4C;QAC5C,MAAMoB,mBAAmB,IAAI,CAACC,mBAAmB,CAACrB;QAElD,kCAAkC;QAClC,MAAMsB,oBAAoBvH,KAAKwH,GAAG,CAAC,IAAIxH,KAAKyH,EAAE,GAAG9G,UAAU8F,QAAQ,KAAK;QAExE,OAAO;YACLD;YACAE;YACAE;YACAE;YACAE;YACAG;YACAE;YACAE;SACD;IACH;IAEQjD,kBAAkB3K,QAAoB,EAAc;QAC1D,IAAIA,SAASC,MAAM,KAAK,GAAG,OAAO,EAAE;QAEpC,MAAM8N,cAAc/N,QAAQ,CAAC,EAAE,CAACC,MAAM;QACtC,MAAM+N,aAAyB,EAAE;QAEjC,qCAAqC;QACrC,MAAMC,OAAO,IAAIlI,MAAMgI,aAAaG,IAAI,CAACC;QACzC,MAAMC,OAAO,IAAIrI,MAAMgI,aAAaG,IAAI,CAAC,CAACC;QAE1CnO,SAASqO,OAAO,CAACC,CAAAA;YACfA,OAAOD,OAAO,CAAC,CAAChK,OAAOkD;gBACrB0G,IAAI,CAAC1G,IAAI,GAAGlB,KAAKU,GAAG,CAACkH,IAAI,CAAC1G,IAAI,EAAElD;gBAChC+J,IAAI,CAAC7G,IAAI,GAAGlB,KAAKkI,GAAG,CAACH,IAAI,CAAC7G,IAAI,EAAElD;YAClC;QACF;QAEA,wBAAwB;QACxBrE,SAASqO,OAAO,CAACC,CAAAA;YACf,MAAME,mBAAmBF,OAAOjH,GAAG,CAAC,CAAChD,OAAOkD;gBAC1C,MAAMkH,QAAQL,IAAI,CAAC7G,IAAI,GAAG0G,IAAI,CAAC1G,IAAI;gBACnC,OAAOkH,UAAU,IAAI,IAAI,AAACpK,CAAAA,QAAQ4J,IAAI,CAAC1G,IAAI,AAAD,IAAKkH;YACjD;YACAT,WAAWvG,IAAI,CAAC+G;QAClB;QAEA,OAAOR;IACT;IAEQnD,gBAAgBb,MAAgB,EAAY;QAClD,IAAIA,OAAO/J,MAAM,KAAK,GAAG,OAAO,EAAE;QAElC,MAAM8G,MAAMV,KAAKU,GAAG,IAAIiD;QACxB,MAAMuE,MAAMlI,KAAKkI,GAAG,IAAIvE;QACxB,MAAMyE,QAAQF,MAAMxH;QAEpB,IAAI0H,UAAU,GAAG,OAAOzE,OAAO3C,GAAG,CAAC,IAAM;QAEzC,OAAO2C,OAAO3C,GAAG,CAACqH,CAAAA,QAAS,AAACA,CAAAA,QAAQ3H,GAAE,IAAK0H;IAC7C;IAEQhB,eAAenB,MAAgB,EAAU;QAC/C,IAAIA,OAAOrM,MAAM,GAAG,GAAG,OAAO;QAE9B,MAAM0O,IAAIrC,OAAOrM,MAAM;QACvB,MAAM2O,OAAO,AAACD,IAAKA,CAAAA,IAAI,CAAA,IAAM;QAC7B,MAAME,OAAOvC,OAAOgB,MAAM,CAAC,CAACC,KAAK/C,IAAM+C,MAAM/C,GAAG;QAChD,MAAMsE,QAAQxC,OAAOgB,MAAM,CAAC,CAACC,KAAK/C,GAAGtE,IAAMqH,MAAOrH,IAAIsE,GAAI;QAC1D,MAAMuE,QAAQ,AAACJ,IAAKA,CAAAA,IAAI,CAAA,IAAM,CAAA,IAAIA,IAAI,CAAA,IAAM;QAE5C,MAAMK,QAAQ,AAACL,CAAAA,IAAIG,QAAQF,OAAOC,IAAG,IAAMF,CAAAA,IAAII,QAAQH,OAAOA,IAAG;QACjE,OAAOnE,MAAMuE,SAAS,IAAIA;IAC5B;IAEQrB,oBAAoBrB,MAAgB,EAAU;QACpD,IAAIA,OAAOrM,MAAM,GAAG,GAAG,OAAO;QAE9B,MAAMgP,OAAO3C,OAAOgB,MAAM,CAAC,CAACC,KAAK/C,IAAM+C,MAAM/C,GAAG,KAAK8B,OAAOrM,MAAM;QAClE,MAAMiP,WAAW5C,OAAOgB,MAAM,CAAC,CAACC,KAAK/C,IAAM+C,MAAMlH,KAAK8I,GAAG,CAAC3E,IAAIyE,MAAM,IAAI,KAAK3C,OAAOrM,MAAM;QAC1F,OAAOoG,KAAK+I,IAAI,CAACF;IACnB;IAEA,mDAAmD;IACnD,iEAAiE;IAEjE,MAAcrL,2BAA2BtE,MAAc,EAAE8P,KAAa,EAAkB;QACtF,sCAAsC;QACtC,OAAO,EAAE;IACX;IAEA,MAAc7K,mBAAmBjF,MAAc,EAAmB;QAChE,0CAA0C;QAC1C,OAAO;IACT;IAEQgF,8BAA8BhE,KAAsB,EAAE4D,IAAW,EAAU;QACjF,kFAAkF;QAClF,OAAO5D,MAAMW,QAAQ,CAACP,QAAQ,GAAG,KAAK,aAAa;IACrD;IAEQmE,gCACNvF,MAAc,EACd0J,OAAe,EACfqG,SAAiB,EACjBnM,SAAiB,EACjBoM,UAAmB,EACT;QACV,MAAM1K,kBAA4B,EAAE;QAEpC,IAAI0K,YAAY;YACd1K,gBAAgB4C,IAAI,CAAC,GAAGlI,OAAO,qCAAqC,EAAE4D,WAAW;YACjF0B,gBAAgB4C,IAAI,CAAC;YACrB5C,gBAAgB4C,IAAI,CAAC;QACvB,OAAO;YACL5C,gBAAgB4C,IAAI,CAAC,GAAGlI,OAAO,4BAA4B,CAAC;YAC5DsF,gBAAgB4C,IAAI,CAAC;QACvB;QAEA,OAAO5C;IACT;IAEQI,mBAAmB3B,SAAiB,EAAU;QACpD,MAAMkM,SAAS;YACb,MAAM,OAAO,KAAK;YAClB,MAAM,OAAO,KAAK;YAClB,OAAO,OAAO,KAAK;YACnB,MAAM,OAAO,KAAK;YAClB,OAAO,OAAO,KAAK,IAAK,UAAU;QACpC;QACA,OAAOA,MAAM,CAAClM,UAAU,IAAI,OAAO,KAAK;IAC1C;IAEQqB,wBAAwBR,IAAW,EAAEhB,SAAiB,EAAEG,SAAiB,EAAoB;QACnG,4DAA4D;QAC5D,MAAMzD,MAAM,IAAIkB;QAChB,MAAMsO,QAAQ/L,cAAc,OAAO,IAAIA,cAAc,OAAO,IAAI;QAChE,OAAO,IAAIvC,KAAKlB,IAAIwJ,OAAO,KAAMgG,QAAQ,KAAK,KAAK;IACrD;IAEA,iCAAiC;IACzBhN,UAAUoN,MAAmB,EAAEC,UAAkB,EAAqD;QAC5G,MAAM5E,aAAazE,KAAK0E,KAAK,CAAC0E,OAAOE,KAAK,CAAC,EAAE,GAAGD;QAChD,OAAO;YACLxP,QAAQuP,OAAOzE,KAAK,CAAC;gBAAC;gBAAG;aAAE,EAAE;gBAACF;gBAAY,CAAC;aAAE;YAC7C1K,aAAaqP,OAAOzE,KAAK,CAAC;gBAACF;gBAAY;aAAE,EAAE;gBAAC,CAAC;gBAAG,CAAC;aAAE;QACrD;IACF;IAEA,MAAc7I,2BAA2BnC,YAA0B,EAAiB;IAClF,wDAAwD;IAC1D;IAEA,MAAcoD,8BAA8B3C,KAAqB,EAAE4D,IAAiB,EAAqB;QACvG,uDAAuD;QACvD,OAAO,EAAE;IACX;IAEQf,0BAA0BwM,MAAgB,EAAU;QAC1D,mCAAmC;QACnC,MAAMC,SAASD,OAAOpD,IAAI,CAAC,CAACC,GAAGC,IAAMD,IAAIC;QACzC,OAAOmD,MAAM,CAACxJ,KAAK0E,KAAK,CAAC8E,OAAO5P,MAAM,GAAG,MAAM;IACjD;IAEQuF,kBAAkBsK,OAA2B,EAAEC,aAAqB,EAAS;QACnF,2CAA2C;QAC3C,OAAO,EAAE;IACX;IAEQrK,uBAAuBD,MAAW,EAAE3D,OAAiB,EAAY;QACvE,0DAA0D;QAC1D,OAAO,EAAE;IACX;IAEQgE,6BAA6BkK,QAAkB,EAAEC,aAAuB,EAAU;QACxF,IAAIC,iBAAiB;QACrB,IAAK,IAAIhK,IAAI,GAAGA,IAAI8J,SAAS/P,MAAM,EAAEiG,IAAK;YACxCgK,kBAAkB7J,KAAK8I,GAAG,CAACa,QAAQ,CAAC9J,EAAE,GAAG+J,aAAa,CAAC/J,EAAE,EAAE;QAC7D;QACA,OAAOG,KAAK+I,IAAI,CAACc,iBAAiBF,SAAS/P,MAAM;IACnD;IAEQsG,0BAA0BhH,MAAc,EAAU;QACxD,MAAM4Q,aAAa;YACjB,aAAa;YACb,gBAAgB;YAChB,qBAAqB;QACvB;QACA,OAAOA,UAAU,CAAC5Q,OAAO,IAAI;IAC/B;IAEQsH,kBAAkBT,SAAiB,EAAEjD,SAAiB,EAAgC;QAC5F,MAAMiN,QAAQhK,YAAYjD;QAC1B,IAAIiN,QAAQ,GAAG,OAAO;QACtB,IAAIA,QAAQ,GAAG,OAAO;QACtB,IAAIA,QAAQ,KAAK,OAAO;QACxB,OAAO;IACT;IAEQ5I,+BAA+BjI,MAAc,EAAE6G,SAAiB,EAAY;QAClF,OAAO;YACL,CAAC,YAAY,EAAE7G,OAAO,QAAQ,CAAC;YAC/B;YACA;SACD;IACH;IAEA,MAAcsI,sBAA4C;QACxD,0CAA0C;QAC1C,OAAO,EAAE;IACX;IAEA,MAAcE,oBAA0C;QACtD,yCAAyC;QACzC,OAAO,EAAE;IACX;IAEA,MAAcE,iBAAuC;QACnD,uCAAuC;QACvC,OAAO,EAAE;IACX;IAEA,MAAcE,qBAA2C;QACvD,yCAAyC;QACzC,OAAO,EAAE;IACX;IAEQK,oBAAoBrE,IAAW,EAAU;QAC/C,IAAIA,KAAKlE,MAAM,GAAG,GAAG,OAAO;QAE5B,MAAMoQ,QAAQlM,IAAI,CAAC,EAAE,CAACE,KAAK;QAC3B,MAAMiM,OAAOnM,IAAI,CAACA,KAAKlE,MAAM,GAAG,EAAE,CAACoE,KAAK;QACxC,MAAMkM,WAAW,AAAC,CAAA,IAAIxP,KAAKoD,IAAI,CAACA,KAAKlE,MAAM,GAAG,EAAE,CAAC+G,SAAS,EAAEqC,OAAO,KAClD,IAAItI,KAAKoD,IAAI,CAAC,EAAE,CAAC6C,SAAS,EAAEqC,OAAO,EAAC,IAAM,CAAA,OAAO,KAAK,KAAK,EAAC,GAAI,OAAO;QAExF,OAAOhD,KAAK8I,GAAG,CAACmB,OAAOD,OAAO,IAAIE,YAAY,GAAG,oBAAoB;IACvE;IAEQzH,oBAAoBR,cAAqB,EAAEkI,SAAiB,EAAY;QAC9E,2CAA2C;QAC3C,MAAM7D,SAASrE,cAAc,CAACA,eAAerI,MAAM,GAAG,EAAE;QACxD,MAAMwQ,aAAa,IAAI1P,KAAK4L,OAAO3F,SAAS;QAC5CyJ,WAAW7H,OAAO,CAAC6H,WAAW5H,OAAO,KAAK2H;QAE1C,OAAO,IAAI,CAAC1M,eAAe,CAAC;YAAC;gBAAE,GAAG6I,MAAM;gBAAE3F,WAAWyJ;YAAW;SAAE;IACpE;IAEQzH,8BACNzJ,MAAc,EACd0J,OAAe,EACfC,SAAiB,EACjBX,UAAkB,EAClBmI,IAAY,EACF;QACV,MAAM7L,kBAA4B,EAAE;QAEpC,MAAM8L,gBAAgB,AAAEzH,CAAAA,YAAYD,OAAM,IAAKA,UAAW;QAE1D,IAAI0H,gBAAgB,IAAI;YACtB9L,gBAAgB4C,IAAI,CAAC,CAAC,yBAAyB,EAAElI,OAAO,EAAE,EAAEoR,cAAc/O,OAAO,CAAC,GAAG,OAAO,EAAE8O,KAAK,KAAK,CAAC;YACzG7L,gBAAgB4C,IAAI,CAAC;YACrB5C,gBAAgB4C,IAAI,CAAC;QACvB,OAAO,IAAIkJ,gBAAgB,IAAI;YAC7B9L,gBAAgB4C,IAAI,CAAC,CAAC,6BAA6B,EAAElI,OAAO,EAAE,EAAEoR,cAAc/O,OAAO,CAAC,GAAG,OAAO,EAAE8O,KAAK,KAAK,CAAC;YAC7G7L,gBAAgB4C,IAAI,CAAC;QACvB,OAAO;YACL5C,gBAAgB4C,IAAI,CAAC,CAAC,2BAA2B,EAAElI,QAAQ;YAC3DsF,gBAAgB4C,IAAI,CAAC;QACvB;QAEA,OAAO5C;IACT;IAEQyF,qBAAqB/K,MAAc,EAAEyH,SAAe,EAAsB;QAChF,sDAAsD;QACtD,OAAOpC;IACT;IA1gCA,aAAc;QATd,uBAAQpD,UAAR,KAAA;QACA,uBAAQiC,SAAR,KAAA;QACA,uBAAQkG,cAAR,KAAA;QACA,uBAAQiH,mBAAR,KAAA;QACA,uBAAQC,sBAAR,KAAA;QACA,uBAAQpR,cAAsB;QAC9B,uBAAQkC,oBAAgC;QACxC,uBAAQsE,qBAAR,KAAA;QAGE,IAAI,CAACzE,MAAM,GAAG,IAAI8D;QAClB,IAAI,CAAC7B,KAAK,GAAG,IAAIqN,kBAAQ,CAAC;YACxBvC,KAAK;YACLvJ,KAAK,OAAO,KAAK,GAAG,mCAAmC;QACzD;QACA,IAAI,CAAC2E,UAAU,GAAGoH,sBAAU,CAACC,WAAW;QACxC,IAAI,CAACJ,eAAe,GAAGK,gCAAe,CAACD,WAAW;QAClD,IAAI,CAACH,kBAAkB,GAAG,IAAIK,sCAAkB;QAChD,IAAI,CAACjL,iBAAiB,GAAG,IAAIX;QAE7B,2BAA2B;QAC3B,IAAI,CAACvG,oBAAoB;QAEzB,uCAAuC;QACvC,IAAI,CAACyK,kBAAkB;IACzB;AA2/BF"}