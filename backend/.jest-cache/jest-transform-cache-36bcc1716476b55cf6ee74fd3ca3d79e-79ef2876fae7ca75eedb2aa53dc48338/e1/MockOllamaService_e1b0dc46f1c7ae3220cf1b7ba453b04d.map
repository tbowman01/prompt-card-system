{"version":3,"sources":["/workspaces/prompt-card-system/backend/src/tests/mocks/MockOllamaService.ts"],"sourcesContent":["/**\n * Mock Ollama Service for Testing\n * \n * Provides a comprehensive mock implementation of the Ollama service\n * for testing without requiring the actual Ollama server.\n */\n\nexport interface OllamaModel {\n  name: string;\n  digest: string;\n  size: number;\n  modified_at: string;\n}\n\nexport interface OllamaResponse {\n  model: string;\n  response: string;\n  done: boolean;\n  total_duration?: number;\n  prompt_eval_count?: number;\n  eval_count?: number;\n}\n\nexport interface ChatMessage {\n  role: 'user' | 'assistant' | 'system';\n  content: string;\n}\n\nexport interface ChatRequest {\n  model: string;\n  messages: ChatMessage[];\n}\n\nexport interface GenerateRequest {\n  model: string;\n  prompt: string;\n}\n\nexport interface MockServiceConfig {\n  isOnline?: boolean;\n  models?: string[];\n  responseDelay?: number;\n  failureRate?: number;\n}\n\nexport class MockOllamaService {\n  private config: Required<MockServiceConfig>;\n  private availableModels: Map<string, OllamaModel> = new Map();\n\n  constructor(config: MockServiceConfig = {}) {\n    this.config = {\n      isOnline: config.isOnline ?? true,\n      models: config.models ?? ['llama3', 'codellama', 'mistral'],\n      responseDelay: config.responseDelay ?? 100,\n      failureRate: config.failureRate ?? 0\n    };\n\n    this.initializeModels();\n  }\n\n  private initializeModels(): void {\n    this.config.models.forEach((modelName) => {\n      this.availableModels.set(modelName, {\n        name: modelName,\n        digest: `sha256:${Math.random().toString(36).substring(2, 15)}`,\n        size: Math.floor(Math.random() * 5000000000) + 1000000000, // 1-5GB\n        modified_at: new Date().toISOString()\n      });\n    });\n  }\n\n  async listModels(): Promise<{ models: OllamaModel[] }> {\n    if (!this.config.isOnline) {\n      throw new Error('Ollama service is offline');\n    }\n\n    await this.simulateDelay();\n    this.simulateFailure();\n\n    return {\n      models: Array.from(this.availableModels.values())\n    };\n  }\n\n  async checkModelExists(modelName: string): Promise<boolean> {\n    if (!this.config.isOnline) {\n      throw new Error('Ollama service is offline');\n    }\n\n    return this.availableModels.has(modelName);\n  }\n\n  async getModelInfo(modelName: string): Promise<any> {\n    if (!this.config.isOnline) {\n      throw new Error('Ollama service is offline');\n    }\n\n    if (!this.availableModels.has(modelName)) {\n      throw new Error(`Model ${modelName} not found`);\n    }\n\n    await this.simulateDelay();\n    this.simulateFailure();\n\n    return {\n      license: 'Apache 2.0',\n      modelfile: `FROM ${modelName}`,\n      parameters: {\n        num_ctx: 4096,\n        temperature: 0.8,\n        top_p: 0.9\n      },\n      details: {\n        format: 'gguf',\n        family: 'llama',\n        families: ['llama'],\n        parameter_size: '7B',\n        quantization_level: 'Q4_0'\n      }\n    };\n  }\n\n  async pullModel(modelName: string): Promise<void> {\n    if (!this.config.isOnline) {\n      throw new Error('Ollama service is offline');\n    }\n\n    await this.simulateDelay(2000); // Longer delay for model pull\n    this.simulateFailure();\n\n    // Add the model to available models\n    this.availableModels.set(modelName, {\n      name: modelName,\n      digest: `sha256:${Math.random().toString(36).substring(2, 15)}`,\n      size: Math.floor(Math.random() * 5000000000) + 1000000000,\n      modified_at: new Date().toISOString()\n    });\n  }\n\n  async deleteModel(modelName: string): Promise<void> {\n    if (!this.config.isOnline) {\n      throw new Error('Ollama service is offline');\n    }\n\n    await this.simulateDelay();\n    this.simulateFailure();\n\n    this.availableModels.delete(modelName);\n  }\n\n  async generate(request: GenerateRequest): Promise<OllamaResponse> {\n    if (!this.config.isOnline) {\n      throw new Error('Ollama service is offline');\n    }\n\n    if (!this.availableModels.has(request.model)) {\n      throw new Error(`Model ${request.model} not found`);\n    }\n\n    await this.simulateDelay();\n    this.simulateFailure();\n\n    const responseText = this.generateMockResponse(request.prompt);\n    \n    return {\n      model: request.model,\n      response: responseText,\n      done: true,\n      total_duration: Math.floor(Math.random() * 5000000000), // nanoseconds\n      prompt_eval_count: request.prompt.split(' ').length,\n      eval_count: responseText.split(' ').length\n    };\n  }\n\n  async *chat(request: ChatRequest): AsyncGenerator<OllamaResponse> {\n    if (!this.config.isOnline) {\n      throw new Error('Ollama service is offline');\n    }\n\n    if (!this.availableModels.has(request.model)) {\n      throw new Error(`Model ${request.model} not found`);\n    }\n\n    this.simulateFailure();\n\n    const lastMessage = request.messages[request.messages.length - 1];\n    const responseText = this.generateMockResponse(lastMessage.content);\n    const words = responseText.split(' ');\n\n    // Stream response word by word\n    for (let i = 0; i < words.length; i++) {\n      await this.simulateDelay(50); // Short delay between words\n      \n      yield {\n        model: request.model,\n        response: words.slice(0, i + 1).join(' '),\n        done: false\n      };\n    }\n\n    // Final response\n    yield {\n      model: request.model,\n      response: responseText,\n      done: true,\n      total_duration: Math.floor(Math.random() * 5000000000),\n      prompt_eval_count: lastMessage.content.split(' ').length,\n      eval_count: words.length\n    };\n  }\n\n  async healthCheck(): Promise<{ status: string; online: boolean; models: string[] }> {\n    return {\n      status: this.config.isOnline ? 'healthy' : 'offline',\n      online: this.config.isOnline,\n      models: this.config.models\n    };\n  }\n\n  // Configuration methods\n  setOnlineStatus(isOnline: boolean): void {\n    this.config.isOnline = isOnline;\n  }\n\n  setResponseDelay(delay: number): void {\n    this.config.responseDelay = delay;\n  }\n\n  setFailureRate(rate: number): void {\n    this.config.failureRate = Math.max(0, Math.min(1, rate));\n  }\n\n  getStats(): Required<MockServiceConfig> & { online: boolean } {\n    return { \n      ...this.config,\n      online: this.config.isOnline\n    };\n  }\n\n  // Private helper methods\n  private async simulateDelay(customDelay?: number): Promise<void> {\n    const delay = customDelay ?? this.config.responseDelay;\n    if (delay > 0) {\n      await new Promise(resolve => setTimeout(resolve, delay));\n    }\n  }\n\n  private simulateFailure(): void {\n    if (Math.random() < this.config.failureRate) {\n      throw new Error('simulated failure');\n    }\n  }\n\n  private generateMockResponse(prompt: string): string {\n    const lowerPrompt = prompt.toLowerCase();\n    \n    // Pattern-based responses\n    if (lowerPrompt.includes('code') || lowerPrompt.includes('function') || lowerPrompt.includes('program')) {\n      return `Here's a code example for your request:\\n\\n\\`\\`\\`javascript\\nfunction example() {\\n  return \"Mock response for code request\";\\n}\\n\\`\\`\\``;\n    }\n    \n    if (lowerPrompt.includes('explain') || lowerPrompt.includes('what') || lowerPrompt.includes('how')) {\n      return \"This is a mock explanation response. In a real scenario, this would provide detailed information about the topic you asked about.\";\n    }\n    \n    if (lowerPrompt.includes('story') || lowerPrompt.includes('tell me')) {\n      return \"Once upon a time, in a mock testing environment, there was a simulated AI assistant that provided helpful responses to test scenarios. This assistant worked diligently to ensure all tests passed successfully.\";\n    }\n    \n    if (lowerPrompt.includes('hello') || lowerPrompt.includes('hi')) {\n      return \"Hello! I'm a mock AI assistant ready to help with your testing needs.\";\n    }\n    \n    // Default response\n    return `Mock response to: \"${prompt}\". This is a simulated response for testing purposes.`;\n  }\n}\n\n// Factory functions for common test scenarios\nexport function createMockOllamaService(scenario: 'healthy' | 'offline' | 'slow' | 'unreliable'): MockOllamaService {\n  switch (scenario) {\n    case 'healthy':\n      return new MockOllamaService({\n        isOnline: true,\n        responseDelay: 100,\n        failureRate: 0\n      });\n      \n    case 'offline':\n      return new MockOllamaService({\n        isOnline: false\n      });\n      \n    case 'slow':\n      return new MockOllamaService({\n        isOnline: true,\n        responseDelay: 2000,\n        failureRate: 0\n      });\n      \n    case 'unreliable':\n      return new MockOllamaService({\n        isOnline: true,\n        responseDelay: 500,\n        failureRate: 0.3\n      });\n      \n    default:\n      return new MockOllamaService();\n  }\n}"],"names":["MockOllamaService","createMockOllamaService","initializeModels","config","models","forEach","modelName","availableModels","set","name","digest","Math","random","toString","substring","size","floor","modified_at","Date","toISOString","listModels","isOnline","Error","simulateDelay","simulateFailure","Array","from","values","checkModelExists","has","getModelInfo","license","modelfile","parameters","num_ctx","temperature","top_p","details","format","family","families","parameter_size","quantization_level","pullModel","deleteModel","delete","generate","request","model","responseText","generateMockResponse","prompt","response","done","total_duration","prompt_eval_count","split","length","eval_count","chat","lastMessage","messages","content","words","i","slice","join","healthCheck","status","online","setOnlineStatus","setResponseDelay","delay","responseDelay","setFailureRate","rate","failureRate","max","min","getStats","customDelay","Promise","resolve","setTimeout","lowerPrompt","toLowerCase","includes","Map","scenario"],"mappings":"AAAA;;;;;CAKC;;;;;;;;;;;QAwCYA;eAAAA;;QA0OGC;eAAAA;;;;;;;;;;;;;;;;AA1OT,MAAMD;IAeHE,mBAAyB;QAC/B,IAAI,CAACC,MAAM,CAACC,MAAM,CAACC,OAAO,CAAC,CAACC;YAC1B,IAAI,CAACC,eAAe,CAACC,GAAG,CAACF,WAAW;gBAClCG,MAAMH;gBACNI,QAAQ,CAAC,OAAO,EAAEC,KAAKC,MAAM,GAAGC,QAAQ,CAAC,IAAIC,SAAS,CAAC,GAAG,KAAK;gBAC/DC,MAAMJ,KAAKK,KAAK,CAACL,KAAKC,MAAM,KAAK,cAAc;gBAC/CK,aAAa,IAAIC,OAAOC,WAAW;YACrC;QACF;IACF;IAEA,MAAMC,aAAiD;QACrD,IAAI,CAAC,IAAI,CAACjB,MAAM,CAACkB,QAAQ,EAAE;YACzB,MAAM,IAAIC,MAAM;QAClB;QAEA,MAAM,IAAI,CAACC,aAAa;QACxB,IAAI,CAACC,eAAe;QAEpB,OAAO;YACLpB,QAAQqB,MAAMC,IAAI,CAAC,IAAI,CAACnB,eAAe,CAACoB,MAAM;QAChD;IACF;IAEA,MAAMC,iBAAiBtB,SAAiB,EAAoB;QAC1D,IAAI,CAAC,IAAI,CAACH,MAAM,CAACkB,QAAQ,EAAE;YACzB,MAAM,IAAIC,MAAM;QAClB;QAEA,OAAO,IAAI,CAACf,eAAe,CAACsB,GAAG,CAACvB;IAClC;IAEA,MAAMwB,aAAaxB,SAAiB,EAAgB;QAClD,IAAI,CAAC,IAAI,CAACH,MAAM,CAACkB,QAAQ,EAAE;YACzB,MAAM,IAAIC,MAAM;QAClB;QAEA,IAAI,CAAC,IAAI,CAACf,eAAe,CAACsB,GAAG,CAACvB,YAAY;YACxC,MAAM,IAAIgB,MAAM,CAAC,MAAM,EAAEhB,UAAU,UAAU,CAAC;QAChD;QAEA,MAAM,IAAI,CAACiB,aAAa;QACxB,IAAI,CAACC,eAAe;QAEpB,OAAO;YACLO,SAAS;YACTC,WAAW,CAAC,KAAK,EAAE1B,WAAW;YAC9B2B,YAAY;gBACVC,SAAS;gBACTC,aAAa;gBACbC,OAAO;YACT;YACAC,SAAS;gBACPC,QAAQ;gBACRC,QAAQ;gBACRC,UAAU;oBAAC;iBAAQ;gBACnBC,gBAAgB;gBAChBC,oBAAoB;YACtB;QACF;IACF;IAEA,MAAMC,UAAUrC,SAAiB,EAAiB;QAChD,IAAI,CAAC,IAAI,CAACH,MAAM,CAACkB,QAAQ,EAAE;YACzB,MAAM,IAAIC,MAAM;QAClB;QAEA,MAAM,IAAI,CAACC,aAAa,CAAC,OAAO,8BAA8B;QAC9D,IAAI,CAACC,eAAe;QAEpB,oCAAoC;QACpC,IAAI,CAACjB,eAAe,CAACC,GAAG,CAACF,WAAW;YAClCG,MAAMH;YACNI,QAAQ,CAAC,OAAO,EAAEC,KAAKC,MAAM,GAAGC,QAAQ,CAAC,IAAIC,SAAS,CAAC,GAAG,KAAK;YAC/DC,MAAMJ,KAAKK,KAAK,CAACL,KAAKC,MAAM,KAAK,cAAc;YAC/CK,aAAa,IAAIC,OAAOC,WAAW;QACrC;IACF;IAEA,MAAMyB,YAAYtC,SAAiB,EAAiB;QAClD,IAAI,CAAC,IAAI,CAACH,MAAM,CAACkB,QAAQ,EAAE;YACzB,MAAM,IAAIC,MAAM;QAClB;QAEA,MAAM,IAAI,CAACC,aAAa;QACxB,IAAI,CAACC,eAAe;QAEpB,IAAI,CAACjB,eAAe,CAACsC,MAAM,CAACvC;IAC9B;IAEA,MAAMwC,SAASC,OAAwB,EAA2B;QAChE,IAAI,CAAC,IAAI,CAAC5C,MAAM,CAACkB,QAAQ,EAAE;YACzB,MAAM,IAAIC,MAAM;QAClB;QAEA,IAAI,CAAC,IAAI,CAACf,eAAe,CAACsB,GAAG,CAACkB,QAAQC,KAAK,GAAG;YAC5C,MAAM,IAAI1B,MAAM,CAAC,MAAM,EAAEyB,QAAQC,KAAK,CAAC,UAAU,CAAC;QACpD;QAEA,MAAM,IAAI,CAACzB,aAAa;QACxB,IAAI,CAACC,eAAe;QAEpB,MAAMyB,eAAe,IAAI,CAACC,oBAAoB,CAACH,QAAQI,MAAM;QAE7D,OAAO;YACLH,OAAOD,QAAQC,KAAK;YACpBI,UAAUH;YACVI,MAAM;YACNC,gBAAgB3C,KAAKK,KAAK,CAACL,KAAKC,MAAM,KAAK;YAC3C2C,mBAAmBR,QAAQI,MAAM,CAACK,KAAK,CAAC,KAAKC,MAAM;YACnDC,YAAYT,aAAaO,KAAK,CAAC,KAAKC,MAAM;QAC5C;IACF;IAEA,OAAOE,KAAKZ,OAAoB,EAAkC;QAChE,IAAI,CAAC,IAAI,CAAC5C,MAAM,CAACkB,QAAQ,EAAE;YACzB,MAAM,IAAIC,MAAM;QAClB;QAEA,IAAI,CAAC,IAAI,CAACf,eAAe,CAACsB,GAAG,CAACkB,QAAQC,KAAK,GAAG;YAC5C,MAAM,IAAI1B,MAAM,CAAC,MAAM,EAAEyB,QAAQC,KAAK,CAAC,UAAU,CAAC;QACpD;QAEA,IAAI,CAACxB,eAAe;QAEpB,MAAMoC,cAAcb,QAAQc,QAAQ,CAACd,QAAQc,QAAQ,CAACJ,MAAM,GAAG,EAAE;QACjE,MAAMR,eAAe,IAAI,CAACC,oBAAoB,CAACU,YAAYE,OAAO;QAClE,MAAMC,QAAQd,aAAaO,KAAK,CAAC;QAEjC,+BAA+B;QAC/B,IAAK,IAAIQ,IAAI,GAAGA,IAAID,MAAMN,MAAM,EAAEO,IAAK;YACrC,MAAM,IAAI,CAACzC,aAAa,CAAC,KAAK,4BAA4B;YAE1D,MAAM;gBACJyB,OAAOD,QAAQC,KAAK;gBACpBI,UAAUW,MAAME,KAAK,CAAC,GAAGD,IAAI,GAAGE,IAAI,CAAC;gBACrCb,MAAM;YACR;QACF;QAEA,iBAAiB;QACjB,MAAM;YACJL,OAAOD,QAAQC,KAAK;YACpBI,UAAUH;YACVI,MAAM;YACNC,gBAAgB3C,KAAKK,KAAK,CAACL,KAAKC,MAAM,KAAK;YAC3C2C,mBAAmBK,YAAYE,OAAO,CAACN,KAAK,CAAC,KAAKC,MAAM;YACxDC,YAAYK,MAAMN,MAAM;QAC1B;IACF;IAEA,MAAMU,cAA8E;QAClF,OAAO;YACLC,QAAQ,IAAI,CAACjE,MAAM,CAACkB,QAAQ,GAAG,YAAY;YAC3CgD,QAAQ,IAAI,CAAClE,MAAM,CAACkB,QAAQ;YAC5BjB,QAAQ,IAAI,CAACD,MAAM,CAACC,MAAM;QAC5B;IACF;IAEA,wBAAwB;IACxBkE,gBAAgBjD,QAAiB,EAAQ;QACvC,IAAI,CAAClB,MAAM,CAACkB,QAAQ,GAAGA;IACzB;IAEAkD,iBAAiBC,KAAa,EAAQ;QACpC,IAAI,CAACrE,MAAM,CAACsE,aAAa,GAAGD;IAC9B;IAEAE,eAAeC,IAAY,EAAQ;QACjC,IAAI,CAACxE,MAAM,CAACyE,WAAW,GAAGjE,KAAKkE,GAAG,CAAC,GAAGlE,KAAKmE,GAAG,CAAC,GAAGH;IACpD;IAEAI,WAA8D;QAC5D,OAAO;YACL,GAAG,IAAI,CAAC5E,MAAM;YACdkE,QAAQ,IAAI,CAAClE,MAAM,CAACkB,QAAQ;QAC9B;IACF;IAEA,yBAAyB;IACzB,MAAcE,cAAcyD,WAAoB,EAAiB;QAC/D,MAAMR,QAAQQ,eAAe,IAAI,CAAC7E,MAAM,CAACsE,aAAa;QACtD,IAAID,QAAQ,GAAG;YACb,MAAM,IAAIS,QAAQC,CAAAA,UAAWC,WAAWD,SAASV;QACnD;IACF;IAEQhD,kBAAwB;QAC9B,IAAIb,KAAKC,MAAM,KAAK,IAAI,CAACT,MAAM,CAACyE,WAAW,EAAE;YAC3C,MAAM,IAAItD,MAAM;QAClB;IACF;IAEQ4B,qBAAqBC,MAAc,EAAU;QACnD,MAAMiC,cAAcjC,OAAOkC,WAAW;QAEtC,0BAA0B;QAC1B,IAAID,YAAYE,QAAQ,CAAC,WAAWF,YAAYE,QAAQ,CAAC,eAAeF,YAAYE,QAAQ,CAAC,YAAY;YACvG,OAAO,CAAC,wIAAwI,CAAC;QACnJ;QAEA,IAAIF,YAAYE,QAAQ,CAAC,cAAcF,YAAYE,QAAQ,CAAC,WAAWF,YAAYE,QAAQ,CAAC,QAAQ;YAClG,OAAO;QACT;QAEA,IAAIF,YAAYE,QAAQ,CAAC,YAAYF,YAAYE,QAAQ,CAAC,YAAY;YACpE,OAAO;QACT;QAEA,IAAIF,YAAYE,QAAQ,CAAC,YAAYF,YAAYE,QAAQ,CAAC,OAAO;YAC/D,OAAO;QACT;QAEA,mBAAmB;QACnB,OAAO,CAAC,mBAAmB,EAAEnC,OAAO,qDAAqD,CAAC;IAC5F;IAlOA,YAAYhD,SAA4B,CAAC,CAAC,CAAE;QAH5C,uBAAQA,UAAR,KAAA;QACA,uBAAQI,mBAA4C,IAAIgF;QAGtD,IAAI,CAACpF,MAAM,GAAG;YACZkB,UAAUlB,OAAOkB,QAAQ,IAAI;YAC7BjB,QAAQD,OAAOC,MAAM,IAAI;gBAAC;gBAAU;gBAAa;aAAU;YAC3DqE,eAAetE,OAAOsE,aAAa,IAAI;YACvCG,aAAazE,OAAOyE,WAAW,IAAI;QACrC;QAEA,IAAI,CAAC1E,gBAAgB;IACvB;AA0NF;AAGO,SAASD,wBAAwBuF,QAAuD;IAC7F,OAAQA;QACN,KAAK;YACH,OAAO,IAAIxF,kBAAkB;gBAC3BqB,UAAU;gBACVoD,eAAe;gBACfG,aAAa;YACf;QAEF,KAAK;YACH,OAAO,IAAI5E,kBAAkB;gBAC3BqB,UAAU;YACZ;QAEF,KAAK;YACH,OAAO,IAAIrB,kBAAkB;gBAC3BqB,UAAU;gBACVoD,eAAe;gBACfG,aAAa;YACf;QAEF,KAAK;YACH,OAAO,IAAI5E,kBAAkB;gBAC3BqB,UAAU;gBACVoD,eAAe;gBACfG,aAAa;YACf;QAEF;YACE,OAAO,IAAI5E;IACf;AACF"}