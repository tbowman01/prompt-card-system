{"version":3,"sources":["/workspaces/prompt-card-system/backend/src/services/assertions/SemanticSimilarityValidator.ts"],"sourcesContent":["import * as tf from '@tensorflow/tfjs-node';\n\nexport interface SimilarityResult {\n  similarity: number;\n  confidence: number;\n  method: string;\n}\n\nexport interface SentimentResult {\n  label: 'positive' | 'negative' | 'neutral';\n  score: number;\n  details?: Record<string, number>;\n}\n\nexport interface LanguageResult {\n  language: string;\n  confidence: number;\n  alternatives?: Array<{ language: string; confidence: number }>;\n}\n\nexport interface ToxicityResult {\n  score: number;\n  categories: Record<string, number>;\n  threshold: number;\n}\n\nexport class SemanticSimilarityValidator {\n  private model: any = null;\n  private modelName: string = 'universal-sentence-encoder';\n  private initialized: boolean = false;\n\n  constructor() {\n    // Initialize TensorFlow.js backend\n    tf.setBackend('cpu');\n  }\n\n  /**\n   * Initialize the semantic similarity validator\n   */\n  async initialize(): Promise<void> {\n    try {\n      console.log('Initializing SemanticSimilarityValidator...');\n      \n      // For now, we'll use a simple fallback implementation\n      // In a production environment, you'd load actual transformer models\n      this.initialized = true;\n      \n      console.log('✅ SemanticSimilarityValidator initialized with fallback implementation');\n    } catch (error) {\n      console.error('❌ Failed to initialize SemanticSimilarityValidator:', error);\n      throw error;\n    }\n  }\n\n  /**\n   * Compute semantic similarity between two texts\n   */\n  async computeSimilarity(text1: string, text2: string): Promise<number> {\n    if (!this.initialized) {\n      throw new Error('SemanticSimilarityValidator not initialized');\n    }\n\n    try {\n      // Fallback implementation using simple text similarity\n      // In production, this would use sentence embeddings\n      const similarity = await this.computeTextSimilarity(text1, text2);\n      return similarity;\n    } catch (error) {\n      console.error('Error computing similarity:', error);\n      throw error;\n    }\n  }\n\n  /**\n   * Analyze sentiment of text\n   */\n  async analyzeSentiment(text: string): Promise<SentimentResult> {\n    if (!this.initialized) {\n      throw new Error('SemanticSimilarityValidator not initialized');\n    }\n\n    try {\n      // Simple sentiment analysis based on keywords\n      const sentiment = this.analyzeSentimentSimple(text);\n      return sentiment;\n    } catch (error) {\n      console.error('Error analyzing sentiment:', error);\n      throw error;\n    }\n  }\n\n  /**\n   * Detect language of text\n   */\n  async detectLanguage(text: string): Promise<LanguageResult> {\n    if (!this.initialized) {\n      throw new Error('SemanticSimilarityValidator not initialized');\n    }\n\n    try {\n      // Simple language detection based on common words\n      const language = this.detectLanguageSimple(text);\n      return language;\n    } catch (error) {\n      console.error('Error detecting language:', error);\n      throw error;\n    }\n  }\n\n  /**\n   * Detect toxicity in text\n   */\n  async detectToxicity(text: string): Promise<ToxicityResult> {\n    if (!this.initialized) {\n      throw new Error('SemanticSimilarityValidator not initialized');\n    }\n\n    try {\n      // Simple toxicity detection based on keyword matching\n      const toxicity = this.detectToxicitySimple(text);\n      return toxicity;\n    } catch (error) {\n      console.error('Error detecting toxicity:', error);\n      throw error;\n    }\n  }\n\n  /**\n   * Get the model name being used\n   */\n  getModelName(): string {\n    return this.modelName;\n  }\n\n  /**\n   * Fallback text similarity using cosine similarity of TF-IDF vectors\n   */\n  private async computeTextSimilarity(text1: string, text2: string): Promise<number> {\n    // Normalize and tokenize texts\n    const tokens1 = this.tokenize(text1.toLowerCase());\n    const tokens2 = this.tokenize(text2.toLowerCase());\n    \n    // Create vocabulary\n    const vocabulary = Array.from(new Set([...tokens1, ...tokens2]));\n    \n    // Create TF-IDF vectors\n    const vector1 = this.createTFIDFVector(tokens1, vocabulary);\n    const vector2 = this.createTFIDFVector(tokens2, vocabulary);\n    \n    // Compute cosine similarity\n    const similarity = this.cosineSimilarity(vector1, vector2);\n    \n    return Math.max(0, Math.min(1, similarity));\n  }\n\n  /**\n   * Simple tokenization\n   */\n  private tokenize(text: string): string[] {\n    return text\n      .replace(/[^\\w\\s]/g, ' ')\n      .split(/\\s+/)\n      .filter(token => token.length > 0);\n  }\n\n  /**\n   * Create TF-IDF vector for tokens\n   */\n  private createTFIDFVector(tokens: string[], vocabulary: string[]): number[] {\n    const vector = new Array(vocabulary.length).fill(0);\n    const tokenCounts = new Map<string, number>();\n    \n    // Count token frequencies\n    tokens.forEach(token => {\n      tokenCounts.set(token, (tokenCounts.get(token) || 0) + 1);\n    });\n    \n    // Calculate TF-IDF\n    vocabulary.forEach((word, index) => {\n      const tf = (tokenCounts.get(word) || 0) / tokens.length;\n      // Simplified IDF (in production, use proper corpus-based IDF)\n      const idf = Math.log(vocabulary.length / (1 + (tokenCounts.has(word) ? 1 : 0)));\n      vector[index] = tf * idf;\n    });\n    \n    return vector;\n  }\n\n  /**\n   * Compute cosine similarity between two vectors\n   */\n  private cosineSimilarity(vector1: number[], vector2: number[]): number {\n    if (vector1.length !== vector2.length) {\n      throw new Error('Vectors must have the same length');\n    }\n    \n    let dotProduct = 0;\n    let norm1 = 0;\n    let norm2 = 0;\n    \n    for (let i = 0; i < vector1.length; i++) {\n      dotProduct += vector1[i] * vector2[i];\n      norm1 += vector1[i] * vector1[i];\n      norm2 += vector2[i] * vector2[i];\n    }\n    \n    const magnitude1 = Math.sqrt(norm1);\n    const magnitude2 = Math.sqrt(norm2);\n    \n    if (magnitude1 === 0 || magnitude2 === 0) {\n      return 0;\n    }\n    \n    return dotProduct / (magnitude1 * magnitude2);\n  }\n\n  /**\n   * Simple sentiment analysis using keyword matching\n   */\n  private analyzeSentimentSimple(text: string): SentimentResult {\n    const positiveWords = [\n      'good', 'great', 'excellent', 'amazing', 'wonderful', 'fantastic', 'awesome',\n      'love', 'like', 'enjoy', 'happy', 'pleased', 'satisfied', 'perfect',\n      'best', 'better', 'brilliant', 'outstanding', 'superb', 'magnificent',\n      'yes', 'correct', 'right', 'accurate', 'successful', 'win', 'victory'\n    ];\n    \n    const negativeWords = [\n      'bad', 'terrible', 'awful', 'horrible', 'disgusting', 'hate', 'dislike',\n      'angry', 'sad', 'disappointed', 'frustrated', 'annoyed', 'upset',\n      'wrong', 'incorrect', 'error', 'fail', 'failure', 'loss', 'defeat',\n      'no', 'not', 'never', 'nothing', 'none', 'worst', 'worse'\n    ];\n    \n    const words = this.tokenize(text.toLowerCase());\n    \n    let positiveScore = 0;\n    let negativeScore = 0;\n    \n    words.forEach(word => {\n      if (positiveWords.includes(word)) {\n        positiveScore++;\n      } else if (negativeWords.includes(word)) {\n        negativeScore++;\n      }\n    });\n    \n    const totalWords = words.length;\n    const netScore = (positiveScore - negativeScore) / Math.max(1, totalWords);\n    \n    let label: 'positive' | 'negative' | 'neutral';\n    let score: number;\n    \n    if (netScore > 0.1) {\n      label = 'positive';\n      score = Math.min(1, netScore * 5);\n    } else if (netScore < -0.1) {\n      label = 'negative';\n      score = Math.min(1, Math.abs(netScore) * 5);\n    } else {\n      label = 'neutral';\n      score = 0.5;\n    }\n    \n    return {\n      label,\n      score,\n      details: {\n        positive: positiveScore,\n        negative: negativeScore,\n        neutral: totalWords - positiveScore - negativeScore,\n        netScore\n      }\n    };\n  }\n\n  /**\n   * Simple language detection using common words\n   */\n  private detectLanguageSimple(text: string): LanguageResult {\n    const languageKeywords = {\n      'en': ['the', 'and', 'is', 'in', 'to', 'of', 'a', 'that', 'it', 'with', 'for', 'as', 'was', 'on', 'are'],\n      'es': ['el', 'la', 'de', 'que', 'y', 'es', 'en', 'un', 'se', 'no', 'te', 'lo', 'le', 'da', 'su'],\n      'fr': ['le', 'de', 'et', 'à', 'un', 'il', 'être', 'et', 'en', 'avoir', 'que', 'pour', 'dans', 'ce', 'son'],\n      'de': ['der', 'die', 'und', 'in', 'den', 'von', 'zu', 'das', 'mit', 'sich', 'des', 'auf', 'für', 'ist', 'im'],\n      'it': ['il', 'di', 'che', 'e', 'la', 'per', 'un', 'in', 'con', 'del', 'da', 'a', 'al', 'le', 'si'],\n      'pt': ['o', 'de', 'que', 'e', 'do', 'da', 'em', 'um', 'para', 'é', 'com', 'não', 'uma', 'os', 'no'],\n      'ru': ['в', 'и', 'не', 'на', 'я', 'быть', 'то', 'он', 'оно', 'как', 'с', 'а', 'но', 'за', 'по'],\n      'zh': ['的', '是', '在', '了', '和', '有', '一', '我', '不', '你', '他', '这', '个', '人', '来']\n    };\n    \n    const words = this.tokenize(text.toLowerCase());\n    const scores: Record<string, number> = {};\n    \n    // Calculate scores for each language\n    Object.entries(languageKeywords).forEach(([lang, keywords]) => {\n      let score = 0;\n      words.forEach(word => {\n        if (keywords.includes(word)) {\n          score++;\n        }\n      });\n      scores[lang] = score / Math.max(1, words.length);\n    });\n    \n    // Find the language with highest score\n    const sortedLanguages = Object.entries(scores)\n      .sort(([, a], [, b]) => b - a);\n    \n    const [topLanguage, topScore] = sortedLanguages[0];\n    \n    return {\n      language: topLanguage,\n      confidence: Math.min(1, topScore * 10),\n      alternatives: sortedLanguages.slice(1, 4).map(([lang, score]) => ({\n        language: lang,\n        confidence: Math.min(1, score * 10)\n      }))\n    };\n  }\n\n  /**\n   * Simple toxicity detection using keyword matching\n   */\n  private detectToxicitySimple(text: string): ToxicityResult {\n    const toxicKeywords = {\n      profanity: ['damn', 'hell', 'crap', 'stupid', 'idiot', 'moron', 'dumb'],\n      harassment: ['hate', 'kill', 'die', 'destroy', 'hurt', 'harm', 'attack'],\n      threats: ['threat', 'threaten', 'violence', 'violent', 'dangerous', 'weapon'],\n      discrimination: ['racist', 'sexist', 'bigot', 'discrimination', 'prejudice'],\n      spam: ['spam', 'advertisement', 'promotion', 'click', 'buy', 'sale', 'offer']\n    };\n    \n    const words = this.tokenize(text.toLowerCase());\n    const categoryScores: Record<string, number> = {};\n    \n    // Calculate scores for each toxicity category\n    Object.entries(toxicKeywords).forEach(([category, keywords]) => {\n      let score = 0;\n      words.forEach(word => {\n        if (keywords.includes(word)) {\n          score++;\n        }\n      });\n      categoryScores[category] = score / Math.max(1, words.length);\n    });\n    \n    // Calculate overall toxicity score\n    const overallScore = Object.values(categoryScores).reduce((sum, score) => sum + score, 0);\n    \n    return {\n      score: Math.min(1, overallScore * 2),\n      categories: categoryScores,\n      threshold: 0.3\n    };\n  }\n\n  /**\n   * Clean up resources\n   */\n  async cleanup(): Promise<void> {\n    if (this.model) {\n      this.model.dispose();\n      this.model = null;\n    }\n    this.initialized = false;\n  }\n}"],"names":["SemanticSimilarityValidator","initialize","console","log","initialized","error","computeSimilarity","text1","text2","Error","similarity","computeTextSimilarity","analyzeSentiment","text","sentiment","analyzeSentimentSimple","detectLanguage","language","detectLanguageSimple","detectToxicity","toxicity","detectToxicitySimple","getModelName","modelName","tokens1","tokenize","toLowerCase","tokens2","vocabulary","Array","from","Set","vector1","createTFIDFVector","vector2","cosineSimilarity","Math","max","min","replace","split","filter","token","length","tokens","vector","fill","tokenCounts","Map","forEach","set","get","word","index","tf","idf","has","dotProduct","norm1","norm2","i","magnitude1","sqrt","magnitude2","positiveWords","negativeWords","words","positiveScore","negativeScore","includes","totalWords","netScore","label","score","abs","details","positive","negative","neutral","languageKeywords","scores","Object","entries","lang","keywords","sortedLanguages","sort","a","b","topLanguage","topScore","confidence","alternatives","slice","map","toxicKeywords","profanity","harassment","threats","discrimination","spam","categoryScores","category","overallScore","values","reduce","sum","categories","threshold","cleanup","model","dispose","setBackend"],"mappings":";;;;+BA0BaA;;;eAAAA;;;kEA1BO;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA0Bb,MAAMA;IAUX;;GAEC,GACD,MAAMC,aAA4B;QAChC,IAAI;YACFC,QAAQC,GAAG,CAAC;YAEZ,sDAAsD;YACtD,oEAAoE;YACpE,IAAI,CAACC,WAAW,GAAG;YAEnBF,QAAQC,GAAG,CAAC;QACd,EAAE,OAAOE,OAAO;YACdH,QAAQG,KAAK,CAAC,uDAAuDA;YACrE,MAAMA;QACR;IACF;IAEA;;GAEC,GACD,MAAMC,kBAAkBC,KAAa,EAAEC,KAAa,EAAmB;QACrE,IAAI,CAAC,IAAI,CAACJ,WAAW,EAAE;YACrB,MAAM,IAAIK,MAAM;QAClB;QAEA,IAAI;YACF,uDAAuD;YACvD,oDAAoD;YACpD,MAAMC,aAAa,MAAM,IAAI,CAACC,qBAAqB,CAACJ,OAAOC;YAC3D,OAAOE;QACT,EAAE,OAAOL,OAAO;YACdH,QAAQG,KAAK,CAAC,+BAA+BA;YAC7C,MAAMA;QACR;IACF;IAEA;;GAEC,GACD,MAAMO,iBAAiBC,IAAY,EAA4B;QAC7D,IAAI,CAAC,IAAI,CAACT,WAAW,EAAE;YACrB,MAAM,IAAIK,MAAM;QAClB;QAEA,IAAI;YACF,8CAA8C;YAC9C,MAAMK,YAAY,IAAI,CAACC,sBAAsB,CAACF;YAC9C,OAAOC;QACT,EAAE,OAAOT,OAAO;YACdH,QAAQG,KAAK,CAAC,8BAA8BA;YAC5C,MAAMA;QACR;IACF;IAEA;;GAEC,GACD,MAAMW,eAAeH,IAAY,EAA2B;QAC1D,IAAI,CAAC,IAAI,CAACT,WAAW,EAAE;YACrB,MAAM,IAAIK,MAAM;QAClB;QAEA,IAAI;YACF,kDAAkD;YAClD,MAAMQ,WAAW,IAAI,CAACC,oBAAoB,CAACL;YAC3C,OAAOI;QACT,EAAE,OAAOZ,OAAO;YACdH,QAAQG,KAAK,CAAC,6BAA6BA;YAC3C,MAAMA;QACR;IACF;IAEA;;GAEC,GACD,MAAMc,eAAeN,IAAY,EAA2B;QAC1D,IAAI,CAAC,IAAI,CAACT,WAAW,EAAE;YACrB,MAAM,IAAIK,MAAM;QAClB;QAEA,IAAI;YACF,sDAAsD;YACtD,MAAMW,WAAW,IAAI,CAACC,oBAAoB,CAACR;YAC3C,OAAOO;QACT,EAAE,OAAOf,OAAO;YACdH,QAAQG,KAAK,CAAC,6BAA6BA;YAC3C,MAAMA;QACR;IACF;IAEA;;GAEC,GACDiB,eAAuB;QACrB,OAAO,IAAI,CAACC,SAAS;IACvB;IAEA;;GAEC,GACD,MAAcZ,sBAAsBJ,KAAa,EAAEC,KAAa,EAAmB;QACjF,+BAA+B;QAC/B,MAAMgB,UAAU,IAAI,CAACC,QAAQ,CAAClB,MAAMmB,WAAW;QAC/C,MAAMC,UAAU,IAAI,CAACF,QAAQ,CAACjB,MAAMkB,WAAW;QAE/C,oBAAoB;QACpB,MAAME,aAAaC,MAAMC,IAAI,CAAC,IAAIC,IAAI;eAAIP;eAAYG;SAAQ;QAE9D,wBAAwB;QACxB,MAAMK,UAAU,IAAI,CAACC,iBAAiB,CAACT,SAASI;QAChD,MAAMM,UAAU,IAAI,CAACD,iBAAiB,CAACN,SAASC;QAEhD,4BAA4B;QAC5B,MAAMlB,aAAa,IAAI,CAACyB,gBAAgB,CAACH,SAASE;QAElD,OAAOE,KAAKC,GAAG,CAAC,GAAGD,KAAKE,GAAG,CAAC,GAAG5B;IACjC;IAEA;;GAEC,GACD,AAAQe,SAASZ,IAAY,EAAY;QACvC,OAAOA,KACJ0B,OAAO,CAAC,YAAY,KACpBC,KAAK,CAAC,OACNC,MAAM,CAACC,CAAAA,QAASA,MAAMC,MAAM,GAAG;IACpC;IAEA;;GAEC,GACD,AAAQV,kBAAkBW,MAAgB,EAAEhB,UAAoB,EAAY;QAC1E,MAAMiB,SAAS,IAAIhB,MAAMD,WAAWe,MAAM,EAAEG,IAAI,CAAC;QACjD,MAAMC,cAAc,IAAIC;QAExB,0BAA0B;QAC1BJ,OAAOK,OAAO,CAACP,CAAAA;YACbK,YAAYG,GAAG,CAACR,OAAO,AAACK,CAAAA,YAAYI,GAAG,CAACT,UAAU,CAAA,IAAK;QACzD;QAEA,mBAAmB;QACnBd,WAAWqB,OAAO,CAAC,CAACG,MAAMC;YACxB,MAAMC,KAAK,AAACP,CAAAA,YAAYI,GAAG,CAACC,SAAS,CAAA,IAAKR,OAAOD,MAAM;YACvD,8DAA8D;YAC9D,MAAMY,MAAMnB,KAAKjC,GAAG,CAACyB,WAAWe,MAAM,GAAI,CAAA,IAAKI,CAAAA,YAAYS,GAAG,CAACJ,QAAQ,IAAI,CAAA,CAAC;YAC5EP,MAAM,CAACQ,MAAM,GAAGC,KAAKC;QACvB;QAEA,OAAOV;IACT;IAEA;;GAEC,GACD,AAAQV,iBAAiBH,OAAiB,EAAEE,OAAiB,EAAU;QACrE,IAAIF,QAAQW,MAAM,KAAKT,QAAQS,MAAM,EAAE;YACrC,MAAM,IAAIlC,MAAM;QAClB;QAEA,IAAIgD,aAAa;QACjB,IAAIC,QAAQ;QACZ,IAAIC,QAAQ;QAEZ,IAAK,IAAIC,IAAI,GAAGA,IAAI5B,QAAQW,MAAM,EAAEiB,IAAK;YACvCH,cAAczB,OAAO,CAAC4B,EAAE,GAAG1B,OAAO,CAAC0B,EAAE;YACrCF,SAAS1B,OAAO,CAAC4B,EAAE,GAAG5B,OAAO,CAAC4B,EAAE;YAChCD,SAASzB,OAAO,CAAC0B,EAAE,GAAG1B,OAAO,CAAC0B,EAAE;QAClC;QAEA,MAAMC,aAAazB,KAAK0B,IAAI,CAACJ;QAC7B,MAAMK,aAAa3B,KAAK0B,IAAI,CAACH;QAE7B,IAAIE,eAAe,KAAKE,eAAe,GAAG;YACxC,OAAO;QACT;QAEA,OAAON,aAAcI,CAAAA,aAAaE,UAAS;IAC7C;IAEA;;GAEC,GACD,AAAQhD,uBAAuBF,IAAY,EAAmB;QAC5D,MAAMmD,gBAAgB;YACpB;YAAQ;YAAS;YAAa;YAAW;YAAa;YAAa;YACnE;YAAQ;YAAQ;YAAS;YAAS;YAAW;YAAa;YAC1D;YAAQ;YAAU;YAAa;YAAe;YAAU;YACxD;YAAO;YAAW;YAAS;YAAY;YAAc;YAAO;SAC7D;QAED,MAAMC,gBAAgB;YACpB;YAAO;YAAY;YAAS;YAAY;YAAc;YAAQ;YAC9D;YAAS;YAAO;YAAgB;YAAc;YAAW;YACzD;YAAS;YAAa;YAAS;YAAQ;YAAW;YAAQ;YAC1D;YAAM;YAAO;YAAS;YAAW;YAAQ;YAAS;SACnD;QAED,MAAMC,QAAQ,IAAI,CAACzC,QAAQ,CAACZ,KAAKa,WAAW;QAE5C,IAAIyC,gBAAgB;QACpB,IAAIC,gBAAgB;QAEpBF,MAAMjB,OAAO,CAACG,CAAAA;YACZ,IAAIY,cAAcK,QAAQ,CAACjB,OAAO;gBAChCe;YACF,OAAO,IAAIF,cAAcI,QAAQ,CAACjB,OAAO;gBACvCgB;YACF;QACF;QAEA,MAAME,aAAaJ,MAAMvB,MAAM;QAC/B,MAAM4B,WAAW,AAACJ,CAAAA,gBAAgBC,aAAY,IAAKhC,KAAKC,GAAG,CAAC,GAAGiC;QAE/D,IAAIE;QACJ,IAAIC;QAEJ,IAAIF,WAAW,KAAK;YAClBC,QAAQ;YACRC,QAAQrC,KAAKE,GAAG,CAAC,GAAGiC,WAAW;QACjC,OAAO,IAAIA,WAAW,CAAC,KAAK;YAC1BC,QAAQ;YACRC,QAAQrC,KAAKE,GAAG,CAAC,GAAGF,KAAKsC,GAAG,CAACH,YAAY;QAC3C,OAAO;YACLC,QAAQ;YACRC,QAAQ;QACV;QAEA,OAAO;YACLD;YACAC;YACAE,SAAS;gBACPC,UAAUT;gBACVU,UAAUT;gBACVU,SAASR,aAAaH,gBAAgBC;gBACtCG;YACF;QACF;IACF;IAEA;;GAEC,GACD,AAAQrD,qBAAqBL,IAAY,EAAkB;QACzD,MAAMkE,mBAAmB;YACvB,MAAM;gBAAC;gBAAO;gBAAO;gBAAM;gBAAM;gBAAM;gBAAM;gBAAK;gBAAQ;gBAAM;gBAAQ;gBAAO;gBAAM;gBAAO;gBAAM;aAAM;YACxG,MAAM;gBAAC;gBAAM;gBAAM;gBAAM;gBAAO;gBAAK;gBAAM;gBAAM;gBAAM;gBAAM;gBAAM;gBAAM;gBAAM;gBAAM;gBAAM;aAAK;YAChG,MAAM;gBAAC;gBAAM;gBAAM;gBAAM;gBAAK;gBAAM;gBAAM;gBAAQ;gBAAM;gBAAM;gBAAS;gBAAO;gBAAQ;gBAAQ;gBAAM;aAAM;YAC1G,MAAM;gBAAC;gBAAO;gBAAO;gBAAO;gBAAM;gBAAO;gBAAO;gBAAM;gBAAO;gBAAO;gBAAQ;gBAAO;gBAAO;gBAAO;gBAAO;aAAK;YAC7G,MAAM;gBAAC;gBAAM;gBAAM;gBAAO;gBAAK;gBAAM;gBAAO;gBAAM;gBAAM;gBAAO;gBAAO;gBAAM;gBAAK;gBAAM;gBAAM;aAAK;YAClG,MAAM;gBAAC;gBAAK;gBAAM;gBAAO;gBAAK;gBAAM;gBAAM;gBAAM;gBAAM;gBAAQ;gBAAK;gBAAO;gBAAO;gBAAO;gBAAM;aAAK;YACnG,MAAM;gBAAC;gBAAK;gBAAK;gBAAM;gBAAM;gBAAK;gBAAQ;gBAAM;gBAAM;gBAAO;gBAAO;gBAAK;gBAAK;gBAAM;gBAAM;aAAK;YAC/F,MAAM;gBAAC;gBAAK;gBAAK;gBAAK;gBAAK;gBAAK;gBAAK;gBAAK;gBAAK;gBAAK;gBAAK;gBAAK;gBAAK;gBAAK;gBAAK;aAAI;QACnF;QAEA,MAAMb,QAAQ,IAAI,CAACzC,QAAQ,CAACZ,KAAKa,WAAW;QAC5C,MAAMsD,SAAiC,CAAC;QAExC,qCAAqC;QACrCC,OAAOC,OAAO,CAACH,kBAAkB9B,OAAO,CAAC,CAAC,CAACkC,MAAMC,SAAS;YACxD,IAAIX,QAAQ;YACZP,MAAMjB,OAAO,CAACG,CAAAA;gBACZ,IAAIgC,SAASf,QAAQ,CAACjB,OAAO;oBAC3BqB;gBACF;YACF;YACAO,MAAM,CAACG,KAAK,GAAGV,QAAQrC,KAAKC,GAAG,CAAC,GAAG6B,MAAMvB,MAAM;QACjD;QAEA,uCAAuC;QACvC,MAAM0C,kBAAkBJ,OAAOC,OAAO,CAACF,QACpCM,IAAI,CAAC,CAAC,GAAGC,EAAE,EAAE,GAAGC,EAAE,GAAKA,IAAID;QAE9B,MAAM,CAACE,aAAaC,SAAS,GAAGL,eAAe,CAAC,EAAE;QAElD,OAAO;YACLpE,UAAUwE;YACVE,YAAYvD,KAAKE,GAAG,CAAC,GAAGoD,WAAW;YACnCE,cAAcP,gBAAgBQ,KAAK,CAAC,GAAG,GAAGC,GAAG,CAAC,CAAC,CAACX,MAAMV,MAAM,GAAM,CAAA;oBAChExD,UAAUkE;oBACVQ,YAAYvD,KAAKE,GAAG,CAAC,GAAGmC,QAAQ;gBAClC,CAAA;QACF;IACF;IAEA;;GAEC,GACD,AAAQpD,qBAAqBR,IAAY,EAAkB;QACzD,MAAMkF,gBAAgB;YACpBC,WAAW;gBAAC;gBAAQ;gBAAQ;gBAAQ;gBAAU;gBAAS;gBAAS;aAAO;YACvEC,YAAY;gBAAC;gBAAQ;gBAAQ;gBAAO;gBAAW;gBAAQ;gBAAQ;aAAS;YACxEC,SAAS;gBAAC;gBAAU;gBAAY;gBAAY;gBAAW;gBAAa;aAAS;YAC7EC,gBAAgB;gBAAC;gBAAU;gBAAU;gBAAS;gBAAkB;aAAY;YAC5EC,MAAM;gBAAC;gBAAQ;gBAAiB;gBAAa;gBAAS;gBAAO;gBAAQ;aAAQ;QAC/E;QAEA,MAAMlC,QAAQ,IAAI,CAACzC,QAAQ,CAACZ,KAAKa,WAAW;QAC5C,MAAM2E,iBAAyC,CAAC;QAEhD,8CAA8C;QAC9CpB,OAAOC,OAAO,CAACa,eAAe9C,OAAO,CAAC,CAAC,CAACqD,UAAUlB,SAAS;YACzD,IAAIX,QAAQ;YACZP,MAAMjB,OAAO,CAACG,CAAAA;gBACZ,IAAIgC,SAASf,QAAQ,CAACjB,OAAO;oBAC3BqB;gBACF;YACF;YACA4B,cAAc,CAACC,SAAS,GAAG7B,QAAQrC,KAAKC,GAAG,CAAC,GAAG6B,MAAMvB,MAAM;QAC7D;QAEA,mCAAmC;QACnC,MAAM4D,eAAetB,OAAOuB,MAAM,CAACH,gBAAgBI,MAAM,CAAC,CAACC,KAAKjC,QAAUiC,MAAMjC,OAAO;QAEvF,OAAO;YACLA,OAAOrC,KAAKE,GAAG,CAAC,GAAGiE,eAAe;YAClCI,YAAYN;YACZO,WAAW;QACb;IACF;IAEA;;GAEC,GACD,MAAMC,UAAyB;QAC7B,IAAI,IAAI,CAACC,KAAK,EAAE;YACd,IAAI,CAACA,KAAK,CAACC,OAAO;YAClB,IAAI,CAACD,KAAK,GAAG;QACf;QACA,IAAI,CAAC1G,WAAW,GAAG;IACrB;IA/UA,aAAc;QAJd,uBAAQ0G,SAAa;QACrB,uBAAQvF,aAAoB;QAC5B,uBAAQnB,eAAuB;QAG7B,mCAAmC;QACnCkD,UAAG0D,UAAU,CAAC;IAChB;AA6UF"}